<html>

<head>

	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>

	<link rel="shortcut icon" href="images/icon.ico">
	<style type="text/css">
		body {
			background-color: #f5f9ff;
		}

		/* Hide both math displays initially, will display based on JS detection */
		.mathjax-mobile,
		.mathml-non-mobile {
			display: none;
		}

		/* Show the MathML content by default on non-mobile devices */
		.show-mathml .mathml-non-mobile {
			display: block;
		}

		.show-mathjax .mathjax-mobile {
			display: block;
		}

		.content-margin-container {
			display: flex;
			width: 100%;
			/* Ensure the container is full width */
			justify-content: left;
			/* Horizontally centers the children in the container */
			align-items: center;
			/* Vertically centers the children in the container */
		}

		.main-content-block {
			width: 70%;
			/* Change this percentage as needed */
			max-width: 1100px;
			/* Optional: Maximum width */
			background-color: #fff;
			padding: 8px 8px 8px 8px;
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		}

		.margin-left-block {
			font-size: 16px;
			width: 15%;
			/* Change this percentage as needed */
			max-width: 130px;
			/* Optional: Maximum width */
			position: relative;
			margin-left: 10px;
			text-align: left;
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			padding: 5px;
		}

		.margin-right-block {
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			font-size: 14px;
			width: 25%;
			/* Change this percentage as needed */
			max-width: 256px;
			/* Optional: Maximum width */
			position: relative;
			text-align: left;
			padding: 10px;
			/* Optional: Adds padding inside the caption */
		}

		img {
			max-width: 100%;
			/* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
		}

		.my-video {
			max-width: 100%;
			/* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
		}

		/* Hide both video displays initially, will display based on JS detection */
		.vid-mobile,
		.vid-non-mobile {
			display: none;
		}

		/* Show the video content by default on non-mobile devices */
		.show-vid-mobile .vid-mobile {
			display: block;
		}

		.show-vid-non-mobile .vid-non-mobile {
			display: block;
		}

		a:link,
		a:visited {
			color: #0e7862;
			/*#1367a7;*/
			text-decoration: none;
		}

		a:hover {
			color: #24b597;
			/*#208799;*/
		}

		h1 {
			font-size: 18px;
			margin-top: 4px;
			margin-bottom: 10px;
		}

		table.header {
			font-weight: 300;
			font-size: 17px;
			flex-grow: 1;
			width: 70%;
			max-width: calc(100% - 290px);
			margin-top: 20px;
			/* Adjust according to the width of .paper-code-tab */
		}

		table td,
		table td * {
			vertical-align: middle;
			position: relative;
		}

		table.paper-code-tab {
			flex-shrink: 0;
			margin-left: 8px;
			margin-top: 8px;
			padding: 0px 0px 0px 8px;
			width: 290px;
			height: 150px;
		}

		.layered-paper {
			/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
			box-shadow:
				0px 0px 1px 1px rgba(0, 0, 0, 0.35),
				/* The top layer shadow */
				5px 5px 0 0px #fff,
				/* The second layer */
				5px 5px 1px 1px rgba(0, 0, 0, 0.35),
				/* The second layer shadow */
				10px 10px 0 0px #fff,
				/* The third layer */
				10px 10px 1px 1px rgba(0, 0, 0, 0.35);
			/* The third layer shadow */
			margin-top: 5px;
			margin-left: 10px;
			margin-right: 30px;
			margin-bottom: 5px;
		}

		hr {
			height: 1px;
			/* Sets the height of the line to 1 pixel */
			border: none;
			/* Removes the default border */
			background-color: #DDD;
			/* Sets the line color to black */
		}

		div.hypothesis {
			width: 80%;
			background-color: #EEE;
			border: 1px solid black;
			border-radius: 10px;
			-moz-border-radius: 10px;
			-webkit-border-radius: 10px;
			font-family: Courier;
			font-size: 18px;
			text-align: center;
			margin: auto;
			padding: 16px 16px 16px 16px;
		}

		div.citation {
			font-size: 0.8em;
			background-color: #fff;
			padding: 10px;
			height: 200px;
		}

		.fade-in-inline {
			position: absolute;
			text-align: center;
			margin: auto;
			-webkit-mask-image: linear-gradient(to right,
					transparent 0%,
					transparent 40%,
					black 50%,
					black 90%,
					transparent 100%);
			mask-image: linear-gradient(to right,
					transparent 0%,
					transparent 40%,
					black 50%,
					black 90%,
					transparent 100%);
			-webkit-mask-size: 8000% 100%;
			mask-size: 8000% 100%;
			animation-name: sweepMask;
			animation-duration: 4s;
			animation-iteration-count: infinite;
			animation-timing-function: linear;
			animation-delay: -1s;
		}

		.fade-in2-inline {
			animation-delay: 1s;
		}

		.inline-div {
			position: relative;
			display: inline-block;
			/* Makes both the div and paragraph inline-block elements */
			vertical-align: top;
			/* Aligns them at the top, you can adjust this to middle, bottom, etc., based on your needs */
			width: 50px;
			/* Optional: Adds space between the div and the paragraph */
		}

		.section-divider {
			height: 1px;
			background-color: #ccc;
			margin: 32px 0 12px 0;
		}

		.main-section-divider {
			height: 2px;
			background-color: #999;
			margin: 8px 0 20px 0;
		}

		.section-title {
			font-size: 24px;
			font-weight: 600;
			margin: 12px 0 16px 0;
			letter-spacing: -0.2px;
		}
	</style>

	<title>Adaptive Computation Transformers for Efficient ECG Time Series Classification</title>
	<meta property="og:title"
		content="Adaptive Computation Transformers for Efficient ECG Time Series Classification" />
	<meta charset="UTF-8">
</head>

<body>

	<div class="content-margin-container">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<table class="header" align=left>
				<tr>
					<td colspan=4>
						<span
							style="font-size: 32px; font-family: 'Helvetica', Courier, monospace; font-weight: bold;">Adaptive
							Computation Transformers for Efficient ECG Time Series Classification</span>
					</td>
				</tr>`
				<tr>
					<td align=left>
						<span style="font-size:17px"><a href="https://github.com/awcheng23">Alice Cheng</a></span>
					</td>
					<td align=left>
						<span style="font-size:17px"><a href="https://github.com/anchris24">Anne Christiono</a></span>
					</td>
				<tr>
					<td colspan=4 align=left><span style="font-size:18px">Final project for 6.7960, MIT</span></td>
				</tr>
			</table>
		</div>
		<div class="margin-right-block">
		</div>
	</div>

	<div class="content-margin-container" id="hero">
		<div class="margin-left-block">
			<!-- table of contents here -->
			<div style="position:fixed; max-width:inherit; top:max(20%,120px)">
				<b style="font-size:20px">Outline</b><br><br>
				<a href="#intro">Introduction</a><br><br>
				<a href="#related-work">Related Work</a><br><br>
				<a href="#methodology">Methodology</a><br><br>
				<a href="#experimental_results">Experimental Results</a><br><br>
				<a href="#discussion">Discussion</a><br><br>
				<a href="#conclusion">Conclusion</a><br><br>
			</div>
		</div>
        

	</div>

	<div class="content-margin-container" id="intro">
		<div class="margin-left-block">
		</div>

		<div class="main-content-block">
			<h1 class="section-title">Introduction</h1>
            Time-series data appear across scientific, medical, and industrial domains, where the goal is often to analyze long sequences for patterns, trends, or anomalies. Unlike static inputs, time-series signals evolve over time and contain dependencies spanning short, medium, and long temporal ranges. Many real-world tasks‚Äîforecasting, anomaly detection, event classification‚Äîrequire models that can process large volumes of sequential data.<br><br>

            One important physiological time series are electrocardiogram (ECG) signals. ECGs record the electrical activity of the heart over time and are widely used to detect arrhythmias (irregular heartbeats), which can often an be an underlying symptom of more severe heart problems. Detecting arrhythmias such as atrial fibrillation requires analyzing tens of seconds to hours of ECG data, even though clinically relevant anomalies may occupy only small portions of the signal. In recent
			years, deep learning models&mdash;particularly convolutional and transformer architectures&mdash;have demonstrated high accuracy in ECG classification.<br><br>

            <img src="/blog/images/arrhythmia_example.png" style="max-width: 90%; height: auto;"><br>

            Because these time series are long and densely sampled, computational efficiency is crucial. For ECG signal analysis, most deep learning models  process all input segments uniformly,
			applying the same computational depth regardless of signal complexity <a href="#ref_1">[1]</a>. This "one-size-fits-all" approach is inefficient, particularly in contexts such as wearable monitors or real-time monitoring.<br><br>

            Adaptive computation presents a promising alternative. By allowing models to dynamically decide how much processing to allocate to each input, adaptive architectures can potentially reduce unnecessary computation while maintaining accuracy. Unambiguous segments can halt early or bypass blocks, while difficult or noisy segments receive additional computation. This enables input-dependent routing of information through the network. In natural language processing and computer vision, adaptive mechanisms such as early-exit transformers, halting networks, and learned sparsity gates have demonstrated that models can learn when more computation is necessary. However, adaptive computation remains largely unexplored for biomedical time series like ECGs, where efficiency and interpretability are equally important. This motivates our investigation into adaptive transformers for ECG anomaly detection.<br><br>

			This project investigates whether adaptive computation transformers can accurately detect arrhythmias in ECG signaals while dynamically allocating computation across the segments Specifically, we examine whether
			adaptive depth and selection models can reduce average computation without sacrificing diagnostic accuracy, the relationship between FLOPs and input class, and the possibility of depth allocation providing insight into local versus global feature usage. By addressing these questions, we aim to provide a framework-level understanding of resource-aware deep learning for ECG classification.
			<br><br>

		</div>
		<div class="margin-right-block" style="transform: translate(0%, -60%);">
			<b>Figure 1.</b> Example ECG signal showing normal sinus rhythm and atrial fibrillation. The irregular, chaotic pattern in the arrhythmic segment demonstrates the variability that makes anomaly detection challenging in long time series.
		</div>
	</div>


	<div class="content-margin-container" id="related-work">
		<div class="margin-left-block"></div>

		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Related Work</h1> Automated ECG classification has evolved
			significantly with deep learning, beginning with convolutional and
			recurrent architectures and moving toward transformer-based approaches. Deep learning methods typically
			apply
			convolutional networks to ECG waveforms, sometimes transforming the signals into spectral or time-frequency
			representations to better capture morphological and frequency-domain features [<a
				href="#ref_ullah">2</a>].<br><br>

			More recent transformer-based models have demonstrated that self-attention can capture long-range
			dependencies across multiple heartbeats, improving the detection of arrhythmias that depend on temporal
			context rather than single-beat morphology. Hybrid designs that combine convolutional layers for local
			feature extraction with transformers for global context have also shown that integrating both local and
			long-range information enhances classification accuracy [<a href="#ref_akan">3</a>]. While these models
			achieve high performance, they operate with a fixed number of layers for every input, ignoring variability
			in segment difficulty or
			noise. This limits efficiency and offers little insight into which portions of the signal drive
			predictions.<br><br>

			Outside ECG-specific work, there have been numerous ways to improve transformer efficiency. Weight sharing,
			using the same learned parameters across multiple layers, reduces model size and computation while
			maintaining performance [<a href="#ref_share">4</a>]. Sparse attention mechanisms limit the number of token
			interactions, focusing computation on the most relevant parts of the input. These techniques improve
			efficiency but do not adapt computation based on input complexity [<a href="#ref_sparse">5</a>].<br><br>

			Mechanisms such as Adaptive Computation Time (ACT) for RNNs allow models to dynamically allocate processing
			steps per
			input, halting early on simpler cases and devoting more computation to difficult ones [<a
				href="#ref_graves">6</a>]. Extensions of this idea to vision transformer architectures include adaptive
			token halting, where low-importance spatial tokens do not progress to deeper layers and are removed from
			computation during inference time. This reduces computational
			cost across depth and has demonstrated preserved accuracy, also revealing interpretable correlations between
			input difficulty and computation depth [<a href="#ref_avit">7</a>]. <br><br>

			Another adaptive approach involves learning class-relevant tokens, essentially reducing the number of tokens
			processed. More commonly seen in image classification tasks, the transformer dynamically identifies the most
			informative regions of an input by learning which patch embeddings are most relevant for the target class.
			Instead of processing every patch uniformly, the model assigns importance scores to each patch and retains
			only those that contribute meaningfully to the prediction. This allows the model to concentrate
			computational resources where they matter most [<a href="#ref_jiang">8</a>].<br><br>

			We want to explore adaptive computation methods for ECG signal analysis because arrhythmic episodes can
			often occupy only small portions of an otherwise normal signal, providing a framework for efficient anomaly
			detection in long time series signals. An adaptive transformer could learn to allocate fewer layers to
			straightforward sinus rhythms, or process only patches that correspond to ECG signal morphology, such as the
			QRS complex. <br><br>

			Altogether, prior work in CNNs, RNNs, and transformers establishes the feasibility and high accuracy of
			automated ECG classification, and adaptive computation in other domains demonstrates the benefits of
			variable-depth processing. Our proposed approach combines these insights for time-series classification.
			We leverage CNNs and transformers to
			capture local and global ECG context while incorporating adaptive computation mechanisms to create a
			classifier with input-dependent
			computation. This framework addresses the limitations of fixed-depth models and provides a
			resource-aware,
			interpretable, and robust paradigm for ECG signal classification.<br><br>

		</div>
		<div class="margin-right-block">
		</div>
	</div>


	<div class="content-margin-container" id="methodology">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Methodology</h1>

			<i>Data and Preprocessing</i><br><br>
			All experiments use the MIT-BIH Atrial Fibrillation Database,
			comprising 23 ten-hour ECG recordings sampled
			at 250 Hz [<a href="#ref_physionet_afdb">9</a>]. We use the first channel of the recording to stay
			consistent with prior work. Each signal has a
			list of rhythm annotations that mark continuous intervals of time. We segment each signal into
			non-overlapping 30-second windows (7500 samples), labeled as
			normal (class 0) if the segment lies entirely in a sinus rhythm (N) interval, and abnormal (class 1) if it
			overlaps with an AFIB (atrial fibrillation), AFL (atrial flutter), or J (AV junctional rhythm)
			interval.<br><br>

			We preprocess the signals with a Butterworth bandpass filter (0.5‚Äì45 Hz) for noise and min-max normalization
			to the range [0,1]. The dataset is split into 70% (19,672 segments) for training, 15% (4,216) validation,
			and 15% (4,216) test.
			Balanced class weights are applied during training due to class imbalance (~60% normal, ~40%
			abnormal).<br><br>

            All experiments in this study were conducted with NVIDIA L40S and H200 GPUs.<br><br>

			<hr>
			<h1>Fixed-Depth Baseline Model</h1>

			The baseline architecture comprises four components: CNN-based patch embedding, sinusoidal positional
			encoding, four transformer encoder layers, and an MLP classification head. The model converts each ECG segment into a sequence of learned (fixed-length) patch embeddings using two convolutional layers to capture local morphology. Positional encodings are added, and the sequence is processed by a four-layer transformer encoder. The resulting patch representations are mean-pooled to form a global embedding, which a small MLP uses to predict the final arrhythmia label.
            <br>

			<b>Training Objective:</b> The model is trained with weighted cross-entropy loss:
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>L</i><sub>task</sub> = ‚àí Œ£<sub><i>c</i></sub> <i>w</i><sub><i>c</i></sub> <i>y</i><sub><i>c</i></sub>
				log œÉ(<i>f</i>(<i>x</i>)<sub><i>c</i></sub>)
			</div>
			<br>
			where <i>w</i><sub><i>c</i></sub> are balanced class weights and œÉ is the softmax function. We use the AdamW
			optimizer with learning rate 3√ó10<sup>‚àí4</sup>, weight decay 10<sup>‚àí4</sup>, gradient clipping at norm 1.0,
			batch size 32, and train for 20 epochs. All inputs traverse all four transformer layers, yielding
			approximately 240k trainable parameters.<br><br>

			<hr>
			<h1>Adaptive Depth Transformer Model</h1>

			The adaptive model shares the same CNN patch embedding, positional encoding, and classification head as the
			baseline, but replaces the fixed transformer stack with an Adaptive Computation Time (ACT)-style halting
			mechanism [<a href="#ref_graves">4</a>]. This enables per-sample, per-layer halting decisions, allowing
			simple inputs to exit early while complex inputs traverse more layers. We use two variants: <b>(i) Non
				weight
				sharing</b>, where each of the four transformer blocks has its own parameters (~855K total), and <b>(ii)
				Weight
				sharing</b>, where a single transformer block is reused across all depths (~457K total), keeping the
			same
			halting logic but halving the parameter footprint. FLOPs reported at "full depth" assume all four layers are
			executed; effective FLOPs during inference depend on the learned halting pattern.<br><br>

			<b>Halting Mechanism:</b> At each transformer layer <i>l</i> ‚àà {0, 1, 2, 3}, after computing the global
			representation <i>z</i><sub><i>l</i></sub> = (1/100) Œ£<sub><i>p</i></sub>
			<i>Z</i><sub><i>l</i></sub>[<i>p</i>], the halting probability is computed as:
			<br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>h</i><sub><i>l</i></sub> = œÉ(Œ≥ ¬∑ <i>z</i><sub><i>l</i></sub>[0] ‚àí Œ≤)
			</div>
			<br>
			where Œ≥ and Œ≤ are learned scalar parameters initialized to 1.0, and the final layer (layer 3) forces halting
			by setting <i>h</i><sub>3</sub> = 1. For each sample, we maintain three state variables: cumulative halting
			mass <i>c</i> (initially 0), remainder mass <i>R</i> (initially 1), and an active mask (initially 1). At
			each layer, we update <i>c</i> ‚Üê <i>c</i> + <i>h</i><sub><i>l</i></sub> ¬∑ mask. If <i>c</i> ‚â• 1 ‚àí Œµ (where Œµ
			= 0.05), the sample halts and contributes <i>R</i> ¬∑ <i>z</i><sub><i>l</i></sub> to the output; otherwise,
			it continues processing and contributes <i>h</i><sub><i>l</i></sub> ¬∑ <i>z</i><sub><i>l</i></sub> to the
			output while updating <i>R</i> ‚Üê <i>R</i> ‚àí <i>h</i><sub><i>l</i></sub>. The final representation is the
			weighted sum <b>output</b> = Œ£<sub><i>l</i></sub> (Œ¥<sub>1,<i>l</i></sub> + Œ¥<sub>2,<i>l</i></sub>).<br><br>

			<b>Training Objective:</b> The adaptive model is trained with a composite loss combining task accuracy and
			computational cost:
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>L</i> = <i>L</i><sub>task</sub> + Œ±<sub>p</sub> ¬∑ ùîº[œÅ]
			</div>
			<br>
			where œÅ is the per-sample ponder cost (effective depth in layers) and Œ±<sub>p</sub> = 5√ó10<sup>‚àí4</sup> is
			the ponder loss weight. The halting parameters Œ≥ and Œ≤ are learned via backpropagation along with all other
			model weights. During inference, each sample adaptively traverses between 1 and 4 layers, with the
			per-sample depth œÅ tracked for subsequent analysis.<br><br>

			<hr>
			<h1>Adaptive Selection Transformer Model</h1>
			While the adaptive-halting model uses early stopping to dynamically reduce depth, the adaptive-selection
			model takes a complementary approach by employing learned sparsity gates to skip computation at the patch,
			head, and block levels within a fixed four-layer depth. Rather than deciding whether to process at all, the
			selection model decides what to process, achieving computational savings through fine-grained pruning of
			redundant tokens, attention heads, and entire transformer blocks. The model introduces small per-layer
			gating
			MLPs (for patch, head, and block decisions); these extra networks increase parameters (~974K total) and
			raise
			the full-depth FLOPs to ~2.76B versus 1.92B for the halting/fixed models, but heavy sparsity at inference
			drives
			the effective FLOPs sharply down.<br><br>

			<b>Gate Architecture:</b> At each layer, the model produces three learnable gate functions:
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>M</i><sub>p,<i>l</i></sub> ‚àà (0,1)<sup>100</sup>: patch (token) selection at layer <i>l</i><br>
				<i>M</i><sub>h,<i>l</i></sub> ‚àà (0,1)<sup>H</sup>: attention head selection at layer <i>l</i><br>
				<i>M</i><sub>b,<i>l</i></sub> ‚àà (0,1): block-wide gating at layer <i>l</i>
			</div>
			<br>
			These gates are computed per-sample from accumulated context <i>Z</i><sub><i>l</i></sub> via a small MLP
			that processes <i>z</i><sub>proc</sub> = ReLU(W<sub>1</sub> ¬∑ <i>Z</i><sub><i>l</i></sub> +
			<i>b</i><sub>1</sub>) and then generates logits for each gate type. Gumbel-sigmoid relaxation enables
			differentiable training, while thresholding at inference produces discrete sparsity patterns.<br><br>

			<b>Gate Application and FLOPs:</b> The patch gate masks token embeddings as X<sub>masked</sub> =
			[x<sub>cls</sub>, <i>M</i><sub>p,<i>l</i></sub>[1:] ‚äô x[1:]], where the class token is always retained. The
			head gate masks attention heads via attention<sub>output</sub> ‚äô <i>M</i><sub>h,<i>l</i></sub>, and the
			block gate modulates residual connections as X ‚Üê X + <i>M</i><sub>b,<i>l</i></sub> ¬∑
			(attention<sub>out</sub> + ff<sub>out</sub>). FLOPs are estimated as:
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				N<sub>eff,<i>l</i></sub> = 1 + <i>M</i><sub>p,<i>l</i></sub>[1:].sum()<br>
				FLOPs<sub><i>l</i></sub> = (N<sub>eff,<i>l</i></sub> / 100) ¬∑ (<i>M</i><sub>h,<i>l</i></sub>.sum() /
				<i>H</i>) ¬∑ <i>M</i><sub>b,<i>l</i></sub> ¬∑ FLOPs<sub>dense,<i>l</i></sub><br>
				compute_fraction = Œ£<sub><i>l</i></sub> FLOPs<sub><i>l</i></sub> / (4 ¬∑ FLOPs<sub>dense</sub>)
			</div>
			<br>
			The triple product captures multiplicative savings from pruning tokens, heads, and blocks jointly, allowing
			significant FLOPs reduction when gates cooperate. The compute fraction ranges from 0 to 1, where lower
			values indicate more aggressive pruning.<br><br>

			<b>Training Objective:</b> Like the adaptive-halting model, the selection model is trained with a composite
			loss balancing task accuracy and computation:
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>L</i> = <i>L</i><sub>task</sub> + Œ±<sub>p</sub> ¬∑ ùîº[compute_fraction]
			</div>
			<br>
			where Œ±<sub>p</sub> = 5√ó10<sup>‚àí4</sup> (same as the halting model). The decision network and gate
			projections add approximately 5% to the total parameter count, keeping the model comparable in size to the
			other approaches.<br><br>
			

			<hr>
			<h1>Research Hypotheses</h1>

			<b>H1: Computational Efficiency.</b> Can adaptive models reduce average computational cost without
			sacrificing classification accuracy?<br>
			We hypothesize that both adaptive approaches will achieve comparable test accuracy to the fixed baseline
			while using fewer FLOPs per sample on average, as measured by effective depth œÅ or compute_fraction.<br><br>

			<b>H2: Input-Dependent Computation.</b> Do adaptive models allocate computation differentially based on
			input characteristics?<br>
			We hypothesize that normal sinus rhythm segments (class 0) will receive lower average depth or compute
			fraction than arrhythmic segments (class 1), reflecting the intuition that regular rhythms require less
			processing than complex or irregular patterns.<br><br>

			<b>H3: Correlation with Signal Complexity.</b> Does the computation allocated by adaptive models correlate
			with intrinsic signal characteristics?<br>
			We hypothesize that samples with higher variance, lower signal-to-noise ratio, or atypical morphology will
			require traversing more layers or retaining more patches/heads/blocks, demonstrating sensitivity to
			variability, noise level, and morphological complexity.<br><br>

			<b>H4: Interpretability and Feature Usage.</b> Do adaptive mechanisms provide interpretable insights into
			which temporal or spatial features drive classification?<br>
			We hypothesize that for the halting model, early halting will correspond to local feature sufficiency while
			late halting indicates reliance on global temporal context, and for the selection model, patch and attention
			head retention patterns will reveal task-relevant time spans and feature dependencies.<br><br>
		</div>
		<div class="margin-right-block">
		</div>
	</div>



	<div class="content-margin-container" id="experimental_results">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Experimental Results</h1>

			We trained all four models on the MIT-BIH Atrial Fibrillation Database and evaluated their performance
			across computational efficiency, accuracy, and model complexity. Our results demonstrate that adaptive
			computation reduces FLOPs and parameters while maintaining or improving classification accuracy.<br><br>
			
			<h1>Model Performance Comparison</h1>
            <img src="/blog/images/test_performance.png" alt="FLOPs over training iterations"
					style="max-width: 80%; height: auto;"><br>

			From Table 1, we see some efficiency accuracy trade-offs. The adaptive model without weight sharing provides the most balanced improvement. The weight-sharing version, while slightly less accurate, cuts the parameter count nearly in half and still lowers computation. The adaptive selection model behaves differently. Although its full-depth computation is higher, its learned sparsity allows it to operate at a fraction of the cost during inference, achieving the largest efficiency gains overall while also delivering the highest accuracy. Together, these results show that both early-halting and learned-sparsity strategies can meaningfully reduce computational load, with each variant offering a different balance of efficiency, model size, and performance. <br><br>
		</div>
		<div class="margin-right-block">
		</div>
	</div>

	<div class="content-margin-container" id="discussion">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Discussion</h1>

            <h1>FLOP Analysis</h1>
			<div style="text-align: center; margin: 20px 0;">
				<img src="/blog/images/flops_over_time.png" alt="FLOPs over training iterations"
					style="max-width: 90%; height: auto;">

			</div>

			The adaptive curves drop below the fixed baseline early in training and remain lower, illustrating <b>H1</b>
			(efficiency without accuracy loss). The WS trajectory shows larger variance, consistent with shared weights
			forcing the halting mechanism to balance reuse against depth‚Äîyet its mean stays below fixed. The smoother No
			WS
			curve indicates a more stable halting policy. Together, these trends support <b>H3</b>: the models learn to
			allocate computation based on signal difficulty, maintaining reduced FLOPs while preserving
			accuracy.<br><br>

			
			<h1>Learning Stability</h1>

			Both adaptive models diverge from the fixed baseline immediately and maintain lower FLOPs throughout
			training, directly confirming <b>H1</b>. Halting achieves 32% reduction (2.14B ‚Üí 1.45B) with smooth, stable
			convergence by step 6K, while Selection achieves 91.1% reduction (2.76B full-depth ‚Üí 0.25B effective)
			through
			an aggressive initial drop followed by exploration (2-6K steps) and stabilization. The distinct temporal
			patterns
			validate <b>H2</b>: both architectures learn when and how to prune computation based on training signals,
			with
			Halting employing deterministic depth-based early exiting and Selection using stochastic Gumbel-Softmax
			gating over patches, heads, and blocks. The emergence of these learned allocation strategies during training
			supports <b>H3</b>‚Äîmodels adapt computation to signal complexity.<br><br>

			The strategy comparison reveals three distinct learning behaviors. Halting achieves 32% reduction with
			smooth convergence, while Selection achieves 91.1% reduction through volatile exploration then
			stabilization,
			directly supporting <b>H1</b>. Learning speed analysis shows Halting front-loads reduction in the first 2K
			steps then refines, whereas Selection maintains aggressive reduction through 6K steps. These temporal
			patterns validate <b>H2</b> and <b>H3</b>: both models learn input-dependent allocation strategies adapted
			to signal complexity.<br><br>

			<div style="text-align: center; margin: 20px 0;">
				<img src="/blog/images/learning_stability_variance.png" alt="Learning stability and variance analysis"
					style="max-width: 70%; height: auto;">
			</div>

			Four-phase breakdown (Warmup 0-2K, Active 2-6K, Refinement 6-10K, Stabilization 10-12.3K) quantifies
			temporal dynamics. Halting's FLOPs drop steeply in Warmup then plateau with minimal variance, while
			Selection shows aggressive early reduction followed by high variance during Active Learning as gates explore
			sparsity patterns. The bottom panels reveal Halting achieves ~32% total reduction with smooth percentage
			change, while Selection achieves ~59% reduction during training. At test time, Selection's aggressive
			sparsity
			yields ~91% reduction (0.25B effective from 2.76B full-depth). Variance analysis (bottom-right) confirms
			Selection's
			exploration phase produces higher instability (œÉ peaks during Active phase) before converging, validating
			<b>H4</b>: deterministic halting yields stable, interpretable learning curves, while stochastic gating
			introduces complexity through exploration.<br><br>

			<hr>
			<h1>Selection Model Activity</h1>
			<div style="text-align: center; margin: 20px 0;">
                <img src="/blog/images/average_ponder_loss.png" alt="Average ponder loss over training"
					style="max-width: 70%; height: auto;"> <br><br>
				<img src="/blog/images/selection_model_activity.png" alt="Selection model active patches over training"
					style="max-width: 70%; height: auto;">
			</div>

			The Selection model assigns each input patch a learned continuation probability using Gumbel-sigmoid
			gates, enabling dynamic depth selection. Beginning at roughly 30% activity, the model‚Äôs initial sparsity
			arises from the Gumbel-Softmax temperature and randomly initialized gate weights, which naturally bias
			computations toward early halting prior to training.During Warmup (0-2K steps), activity drops sharply to
			~15-20% as gates rapidly discover that
			aggressive sparsity is viable without accuracy loss. The Active Learning phase (2-6K steps) exhibits high
			variance in activity levels (ranging 10-25%) as gates explore the accuracy-sparsity trade-off, corresponding
			to the FLOPs volatility observed earlier. By Stabilization (10-12.3K steps), activity converges to ~14% (86%
			sparsity), meaning only 1 in 7 patches/heads/blocks remain active on average. This learned sparsity pattern
			directly validates <b>H2</b>: the model adapts computation on a per-input basis, allocating resources only
			where needed. The convergence to extreme sparsity while maintaining 99.26% accuracy confirms
			<b>H1</b>‚Äîcomputational efficiency without performance degradation.<br><br>

			<div style="text-align: center; margin: 20px 0;">
				<img src="/blog/images/low_high_compute_grid.png" alt="Low and high compute examples"
					style="max-width: 70%; height: auto;">
			</div>

		</div>
		<div class="margin-right-block">

			<p style="transform: translate(0%, -300%);">
				<b>Table 1.</b> <i> Comprehensive model performance metrics.</i> All models are evaluated on the same
				test
				set
				(AFDB, 2-class: normal vs. atrial fibrillation). FLOPs reported as billions of floating-point operations
				per
				forward pass. "Avg FLOPs (Test)" reflects actual computation after halting/gating during inference.
				Parameter counts include all trainable weights. WS = weight sharing. Œî Accuracy shows improvement or
				degradation relative to the fixed baseline.
			</p>
			<p style="transform: translate(0%, -200%);">
				<b>Figure 3.</b> FLOPs per forward pass across training. Fixed (blue) stays flat at 1.92B. Adaptive
				(No WS, orange) converges to ~1.69B (‚âà12% reduction) with low variance. Adaptive (WS, magenta)
				starts higher but settles near ~1.51B while fluctuating more, reflecting the uncertainty from shared
				weights.
			</p>
			<p style="transform: translate(0%, 75%);">
				<b>Figure 4.</b> Learning phases breakdown with vertical dividers at 2K, 6K, 10K steps
				marking Warmup, Active Learning, Refinement, and Stabilization phases. (Top-left) Halting (WS) model:
				showing steep Warmup drop then plateau,
				annotated with phase labels. (Top-right) Selection model: showing aggressive early drop, volatile Active
				phase (2-6K), then stabilization, annotated with phase
				labels. (Bottom-left) Percent change from initial FLOPs: smoothed curves for both models showing
				Halting achieving ~32% reduction gradually, Selection achieving ~59% reduction during training with
				steeper initial
				trajectory. (Bottom-right) Variance analysis: rolling 200-step standard deviation for both models
				across training, revealing Halting's consistently low variance vs. Selection's elevated variance
				during Active Learning phase (2-6K) before decreasing.
			</p>
			<p style="transform: translate(0%, 225%);">
				<b>Figure 6.</b> Selection model active parameter fraction across training steps. Starts at ~30%
				activity (70% sparsity) due to Gumbel-Softmax temperature initialization and random gate weights that
				favor moderate pruning before learning. Drops sharply during Warmup (0-2K) to ~15-20% as gates
				discover aggressive sparsity is viable. Exhibits high variance (10-25% range) during Active Learning
				phase (2-6K) as gates explore accuracy-sparsity trade-off. Converges to ~14% activity (86% sparsity,
				only 1 in 7 components active) by Stabilization phase (10-12.3K), demonstrating learned extreme
				sparsity while maintaining 99.26% test accuracy.
			</p>

		</div>
	</div>

	<div class="content-margin-container" id="conclusion">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Conclusion</h1>

			This work demonstrates that transformer-based ECG models can achieve significant computational
			efficiency through input-dependent routing mechanisms. Both early-halting and learned-sparsity approaches
			reduce average model depth without sacrificing diagnostic accuracy‚ÄîAdaptive-Halting achieves 32% FLOPs
			reduction while maintaining 99.33% accuracy, while Adaptive-Selection achieves 91.1% reduction at 99.26%
			accuracy. The observation that models autonomously learn to allocate deeper computation to morphologically
			complex signals suggests that transformer architectures, when equipped with adaptive depth mechanisms, can
			learn interpretable hierarchies of feature abstraction: shallow layers extract signal morphology sufficient
			for routine patterns, while deeper layers disambiguate complex arrhythmias.<br><br>

			From an architectural perspective, this work highlights the interplay between model capacity, regularization
			design, and learned computation allocation. The ponder loss regularization enables explicit optimization of
			the efficiency-accuracy frontier without post-hoc pruning or distillation, making the computation budget a
			design parameter rather than a computational constraint. However, practical deployment of such methods
			requires addressing several architectural and empirical gaps. The expressiveness of the halting controller
			remains a fundamental question‚Äîthe binary early-exit mechanism may not capture fine-grained routing patterns
			in deeper layers. Comparative architectural studies against pruning, quantization, and knowledge
			distillation on equivalent model families would clarify whether adaptive depth represents a distinct
			efficiency paradigm or a complementary technique. Furthermore, theoretical understanding of why
			input-dependent depth allocation succeeds in time-series classification remains limited; future work should
			investigate the relationship between signal complexity metrics, layer-wise feature specialization, and
			optimal halting depth through causal analysis and attention visualization. Extending this framework to
			multi-lead recordings, diverse cardiac pathologies, and other physiological signal modalities would
			establish whether adaptive depth allocation is a general principle for biomedical deep learning or specific
			to single-lead ECG classification.<br><br>

		</div>
		<div class="margin-right-block">
		</div>
	</div>

	<div class="content-margin-container" id="citations">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class='citation' id="references" style="height:auto"><br>
				<span style="font-size:16px">References</span><br><br>
				<a id="ref_1"></a>[1] <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12293">
					ECG-TransCovNet: A hybrid transformer model for accurate arrhythmia detection using
					Electrocardiogram signals</a>,
				Shah, et al., 2024<br><br>
				<a id="ref_ullah"></a>[2] <a href="https://arxiv.org/abs/2005.06902">
					Classification of Arrhythmia by Using Deep Learning with 2-D ECG Spectral Image
					Representation</a>,
				Ullah, et al., 2020<br><br>
				<a id="ref_akan"></a>[3] <a href="https://arxiv.org/abs/2401.05434">

					ECGformer: Leveraging transformer for ECG heartbeat arrhythmia classification</a>,
				Akan, et al., 2024<br><br>
				<a id="ref_share"></a>[4] <a href="https://arxiv.org/abs/1909.11942">
					ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</a>, Lan et al.,
				2019<br><br>
				<a id="ref_sparse"></a>[5] <a href="https://arxiv.org/abs/2406.16747">
					Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers</a>, Lou
				et al., 2024<br><br>
				<a id="ref_graves"></a>[6] <a href="https://arxiv.org/abs/1603.08983">
					Adaptive Computation Time for Recurrent Neural Networks</a>, Graves, 2016<br><br>
				<a id="ref_avit"></a>[7] <a
					href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_A-ViT_Adaptive_Tokens_for_Efficient_Vision_Transformer_CVPR_2022_paper.pdf">
					A-ViT: Adaptive Tokens for Efficient Vision Transformer</a>, Yin et al., 2022 <br><br>
				<a id="ref_jiang"></a>[8] <a href="https://arxiv.org/html/2405.03722v1">
					Class-relevant Patch Embedding Selection for Few-Shot Image Classification</a>, Yuan et al., 2024
				<br><br>
				<a id="ref_physionet_afdb"></a>[9] <a href="https://physionet.org/content/afdb/1.0.0/">
					MIT-BIH Atrial Fibrillation Database</a>, Goldberger et al., 2000 <br><br>

			</div>
		</div>
		<div class="margin-right-block">
			<!-- margin notes for reference block here -->
		</div>
	</div>

</body>

</html>