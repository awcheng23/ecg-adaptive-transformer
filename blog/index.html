<html>

<head>

	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>

	<link rel="shortcut icon" href="images/icon.ico">
	<style type="text/css">
		body {
			background-color: #f5f9ff;
		}

		/* Hide both math displays initially, will display based on JS detection */
		.mathjax-mobile,
		.mathml-non-mobile {
			display: none;
		}

		/* Show the MathML content by default on non-mobile devices */
		.show-mathml .mathml-non-mobile {
			display: block;
		}

		.show-mathjax .mathjax-mobile {
			display: block;
		}

		.content-margin-container {
			display: flex;
			width: 100%;
			/* Ensure the container is full width */
			justify-content: left;
			/* Horizontally centers the children in the container */
			align-items: center;
			/* Vertically centers the children in the container */
		}

		.main-content-block {
			width: 70%;
			/* Change this percentage as needed */
			max-width: 1100px;
			/* Optional: Maximum width */
			background-color: #fff;
			border-left: 1px solid #DDD;
			border-right: 1px solid #DDD;
			padding: 8px 8px 8px 8px;
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		}

		.margin-left-block {
			font-size: 14px;
			width: 15%;
			/* Change this percentage as needed */
			max-width: 130px;
			/* Optional: Maximum width */
			position: relative;
			margin-left: 10px;
			text-align: left;
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			padding: 5px;
		}

		.margin-right-block {
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			font-size: 14px;
			width: 25%;
			/* Change this percentage as needed */
			max-width: 256px;
			/* Optional: Maximum width */
			position: relative;
			text-align: left;
			padding: 10px;
			/* Optional: Adds padding inside the caption */
		}

		img {
			max-width: 100%;
			/* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
		}

		.my-video {
			max-width: 100%;
			/* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
		}

		/* Hide both video displays initially, will display based on JS detection */
		.vid-mobile,
		.vid-non-mobile {
			display: none;
		}

		/* Show the video content by default on non-mobile devices */
		.show-vid-mobile .vid-mobile {
			display: block;
		}

		.show-vid-non-mobile .vid-non-mobile {
			display: block;
		}

		a:link,
		a:visited {
			color: #0e7862;
			/*#1367a7;*/
			text-decoration: none;
		}

		a:hover {
			color: #24b597;
			/*#208799;*/
		}

		h1 {
			font-size: 18px;
			margin-top: 4px;
			margin-bottom: 10px;
		}

		table.header {
			font-weight: 300;
			font-size: 17px;
			flex-grow: 1;
			width: 70%;
			max-width: calc(100% - 290px);
			/* Adjust according to the width of .paper-code-tab */
		}

		table td,
		table td * {
			vertical-align: middle;
			position: relative;
		}

		table.paper-code-tab {
			flex-shrink: 0;
			margin-left: 8px;
			margin-top: 8px;
			padding: 0px 0px 0px 8px;
			width: 290px;
			height: 150px;
		}

		.layered-paper {
			/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
			box-shadow:
				0px 0px 1px 1px rgba(0, 0, 0, 0.35),
				/* The top layer shadow */
				5px 5px 0 0px #fff,
				/* The second layer */
				5px 5px 1px 1px rgba(0, 0, 0, 0.35),
				/* The second layer shadow */
				10px 10px 0 0px #fff,
				/* The third layer */
				10px 10px 1px 1px rgba(0, 0, 0, 0.35);
			/* The third layer shadow */
			margin-top: 5px;
			margin-left: 10px;
			margin-right: 30px;
			margin-bottom: 5px;
		}

		hr {
			height: 1px;
			/* Sets the height of the line to 1 pixel */
			border: none;
			/* Removes the default border */
			background-color: #DDD;
			/* Sets the line color to black */
		}

		div.hypothesis {
			width: 80%;
			background-color: #EEE;
			border: 1px solid black;
			border-radius: 10px;
			-moz-border-radius: 10px;
			-webkit-border-radius: 10px;
			font-family: Courier;
			font-size: 18px;
			text-align: center;
			margin: auto;
			padding: 16px 16px 16px 16px;
		}

		div.citation {
			font-size: 0.8em;
			background-color: #fff;
			padding: 10px;
			height: 200px;
		}

		.fade-in-inline {
			position: absolute;
			text-align: center;
			margin: auto;
			-webkit-mask-image: linear-gradient(to right,
					transparent 0%,
					transparent 40%,
					black 50%,
					black 90%,
					transparent 100%);
			mask-image: linear-gradient(to right,
					transparent 0%,
					transparent 40%,
					black 50%,
					black 90%,
					transparent 100%);
			-webkit-mask-size: 8000% 100%;
			mask-size: 8000% 100%;
			animation-name: sweepMask;
			animation-duration: 4s;
			animation-iteration-count: infinite;
			animation-timing-function: linear;
			animation-delay: -1s;
		}

		.fade-in2-inline {
			animation-delay: 1s;
		}

		.inline-div {
			position: relative;
			display: inline-block;
			/* Makes both the div and paragraph inline-block elements */
			vertical-align: top;
			/* Aligns them at the top, you can adjust this to middle, bottom, etc., based on your needs */
			width: 50px;
			/* Optional: Adds space between the div and the paragraph */
		}
	</style>

	<title>Adaptive-Depth Transformers for Efficient and Robust ECG Classification</title>
	<meta property="og:title" content="Adaptive-Depth Transformers for Efficient and Robust ECG Classification" />
	<meta charset="UTF-8">
</head>

<body>

	<div class="content-margin-container">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<table class="header" align=left>
				<tr>
					<td colspan=4>
						<span
							style="font-size: 32px; font-family: 'Helvetica', Courier, monospace; /* Adds fallbacks */">Adaptive-Depth
							Transformers for Efficient and Robust ECG Classification</span>
					</td>
				</tr>`
				<tr>
					<td align=left>
						<span style="font-size:17px"><a href="https://github.com/awcheng23">Alice Cheng</a></span>
					</td>
					<td align=left>
						<span style="font-size:17px"><a href="https://github.com/anchris24">Anne Christiono</a></span>
					</td>
				<tr>
					<td colspan=4 align=left><span style="font-size:18px">Final project for 6.7960, MIT</span></td>
				</tr>
			</table>
		</div>
		<div class="margin-right-block">
		</div>
	</div>

	<div class="content-margin-container" id="intro">
		<div class="margin-left-block">
			<!-- table of contents here -->
			<div style="position:fixed; max-width:inherit; top:max(20%,120px)">
				<b style="font-size:16px">Outline</b><br><br>
				<a href="#intro">Introduction</a><br><br>
				<a href="#prior_work">Prior Work</a><br><br>
				<a href="#methodology">Methodology</a><br><br>
				<a href="#experimental_results">Experimental Results</a><br><br>
				<a href="#implications_and_limitations">Implications and Limitations</a><br><br>
				<a href="#conclusion">Conclusion</a><br><br>
			</div>
		</div>
		<div class="main-content-block">
			<!--You can embed an image like this:-->
			<img src="./images/morphology_101_140.png" width=512px />
		</div>
		<div class="margin-right-block">
			<b>Figure 1.</b> Example ECG waveform illustrating key morphological components, including P waves, QRS
			complexes,
			T waves, PR and ST segments, and the RR interval between successive beats, which together define the
			temporal structure that arrhythmia classifiers must learn to interpret.
		</div>
	</div>

	<div class="content-margin-container" id="intro">
		<div class="margin-left-block">
		</div>

		<div class="main-content-block">

			The source code for the work described in this study can be found <a href="">XXXXXXX ADD
				XXXXXXX.</a><br><br>
			<h1>Introduction</h1>
			Electrocardiograms (ECGs) are a cornerstone of cardiac diagnostics, widely used to detect arrhythmias
			such as atrial fibrillation, premature ventricular contractions, and ST-segment deviations. In recent
			years, deep learning models—particularly convolutional and transformer architectures—have demonstrated
			high accuracy in ECG classification. However, most of these models process all input segments uniformly,
			applying the same computational depth regardless of signal complexity <a href="#ref_1">[1]</a>. As a result,
			clean or simple ECG
			segments are often over-processed, while complex or noisy segments may not receive sufficient analysis.
			This “one-size-fits-all” approach is inefficient, particularly in contexts where energy and latency are
			constrained, such as wearable monitors or bedside diagnostic devices. <br><br>

			<img src="./images/transformer_intro.jpg" width=600px />

			Adaptive computation presents a promising alternative. By allowing models to dynamically decide how much
			processing to allocate to each input, adaptive-depth architectures can potentially reduce unnecessary
			computation while maintaining accuracy. In natural language processing and computer vision, mechanisms
			such as Adaptive Computation Time (ACT) and adaptive halting in transformers have demonstrated that
			models can allocate more computation to difficult or ambiguous inputs, achieving efficiency gains and
			providing interpretable insights into input complexity. <br><br>

			Despite these advances, adaptive computation remains largely unexplored in the context of biomedical
			signals. ECGs are inherently variable: rhythms differ in morphology, duration, and susceptibility to
			noise. An adaptive model could, in principle, allocate fewer layers to simple sinus rhythms while using
			deeper processing for irregular or artifact-laden segments. This could not only improve computational
			efficiency but also reveal interpretable patterns linking model behavior to clinical signal
			characteristics. <br><br>

			This project investigates whether an adaptive halting transformer can dynamically allocate computation
			across ECG segments, comparing it to a fixed-depth baseline. Specifically, we examine whether
			adaptive-depth models can reduce average computation without sacrificing diagnostic accuracy, whether
			computation correlates with input difficulty or noise, and whether depth allocation provides insight
			into local versus global feature usage. By addressing these questions, we aim to provide a
			framework-level understanding of resource-aware deep learning for ECG classification.
			<br><br>

		</div>
		<div class="margin-right-block" style="transform: translate(0%, -20%);">
			<!-- you can move the margin notes up and down with translate -->
			<b>Figure 2.</b> From <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12293">Shah et
				al. (2024)
			</a>: <i>ECG-TransCovNet</i>. Features are extracted from ECG signals using a convolutional neural network
			and passed into a vanilla transformer to detect arrhythmias.
		</div>
	</div>


	<!-- <div class="margin-right-block">
		<b>Figure 2.</b> From <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12293">Shah et
			al. (2024)
		</a>: <i>ECG-TransCovNet</i>. A ViT splits an image into
		patches, encodes them with positional embeddings, processes them through a transformer encoder, and uses a
		classification head to predict image classes.
	</div>
	</div> -->


	<div class="content-margin-container" id="prior-work">
		<div class="margin-left-block"></div>

		<div class="main-content-block">
			<h1>Prior Work</h1>

			Automated ECG classification has evolved significantly with deep learning, beginning with convolutional and
			recurrent architectures and moving toward transformer-based approaches. Early methods typically applied
			convolutional networks to ECG waveforms, sometimes transforming the signals into spectral or time-frequency
			representations to better capture morphological and frequency-domain features. These models effectively
			classify common arrhythmias and establish strong benchmark performance, but they process all segments
			uniformly, applying the same computational resources to simple and complex signals alike. [<a
				href="#ref_ullah">2</a>] This limits
			efficiency and offers little insight into which inputs require more processing. <br><br>

			More recent transformer-based models have demonstrated that self-attention can capture long-range
			dependencies across multiple heartbeats, improving the detection of arrhythmias that depend on temporal
			context rather than single-beat morphology. Hybrid designs that combine convolutional layers for local
			feature extraction with transformers for global context have also shown that integrating both local and
			long-range information enhances classification accuracy [<a href="#ref_akan">3</a>]. While these models
			achieve high performance, they
			still operate with a fixed number of layers for every input, ignoring variability in segment difficulty or
			noise. As a result, they may over-process simple segments while under-analyzing challenging or noisy
			windows, and provide limited interpretability regarding which portions of the signal drive
			predictions.<br><br>

			Recent approaches also process continuous ECG segments end-to-end, simultaneously detecting and classifying
			heartbeats without explicit segmentation. By modeling inter-beat dependencies directly, these methods reduce
			preprocessing complexity and capture more holistic temporal information. Nonetheless, these too maintain a
			fixed computational depth, treating all segments equally regardless of clinical complexity or signal
			quality. This leaves potential efficiency gains unexploited and limits the model’s ability to adapt to
			challenging inputs.<br><br>

			Outside ECG-specific work, adaptive computation has been explored in machine learning more broadly.
			Mechanisms such as Adaptive Computation Time (ACT) allow models to dynamically allocate processing steps per
			input, halting early on simpler cases and devoting more computation to difficult ones [<a
				href="#ref_graves">4</a>]. Extensions of this
			idea to transformer architectures have demonstrated that adaptive halting can reduce average computational
			cost while preserving accuracy, and can also reveal interpretable correlations between input difficulty and
			computation depth.<br><br>

			Applying adaptive computation to ECG analysis is particularly promising because cardiac signals vary widely
			in morphology, rhythm, and noise. An adaptive-depth transformer could allocate fewer layers to
			straightforward sinus rhythms, while dedicating more processing to arrhythmias with complex or ambiguous
			patterns. This dynamic allocation offers several advantages: improved computational efficiency, better
			handling of noisy or low-confidence inputs, and insights into which features or time spans drive
			classification decisions.<br><br>

			Altogether, prior work in CNNs, RNNs, and transformers establishes the feasibility and high accuracy of
			automated ECG classification, while adaptive computation in other domains demonstrates the benefits of
			variable-depth processing. Our proposed approach combines these insights: it leverages transformers to
			capture local and global ECG features while introducing adaptive halting, enabling input-dependent
			computation. This framework addresses the limitations of fixed-depth models and provides a resource-aware,
			interpretable, and robust paradigm for ECG classification.<br><br>
		</div>

		<div class="margin-right-block">
			Margin note: situate your work at the intersection of ECG modelling, transformer architectures, and adaptive
			computation.
		</div>
	</div>


	<div class="content-margin-container">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<h1>Methodology</h1>

			<i>Data Processing:</i><br><br>
			All experiments use the MIT-BIH Arrhythmia Database, where each patient record consists of a continuous ECG
			waveform and beat-level annotations. Our preprocessing pipeline standardizes these signals before model
			training. For each patient, we load the raw ECG waveform and its associated annotations. A 0.5 - 45 Hz
			Butterworth bandpass filter removes baseline wander and high-frequency noise. This is applied in the
			original sampling rate to preserve the alignment between waveform and annotated beat locations. Each entire
			patient recording is normalized to the range [0,1]. Normalization is performed before
			segmentation, ensuring that windows from the same record share a consistent amplitude scale.

		</div>
		<div class="margin-right-block">
			A caption for the video could go here.
		</div>
	</div>

	<div class="content-margin-container" id="implications_and_limitations">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<h1>Implications and limitations</h1>
			Let's end with some discussion of the implications and limitations.
		</div>
		<div class="margin-right-block">
		</div>
	</div>

	<div class="content-margin-container" id="citations">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class='citation' id="references" style="height:auto"><br>
				<span style="font-size:16px">References:</span><br><br>
				<a id="ref_1"></a>[1] <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12293">
					ECG-TransCovNet: A hybrid transformer model for accurate arrhythmia detection using
					Electrocardiogram signals</a>,
				Shah, et al., 2024<br><br>
				<a id="ref_ullah"></a>[2] <a href="https://arxiv.org/abs/2005.06902">
					Classification of Arrhythmia by Using Deep Learning with 2-D ECG Spectral Image Representation</a>,
				Ullah, et al., 2020<br><br>
				<a id="ref_akan"></a>[3] <a href="https://arxiv.org/abs/2401.05434">

					ECGformer: Leveraging transformer for ECG heartbeat arrhythmia classification</a>,
				Akan, et al., 2024<br><br>
				<a id="ref_graves"></a>[4] <a href="https://arxiv.org/abs/1603.08983">
					Adaptive Computation Time for Recurrent Neural Networks</a>, Graves, 2016<br><br>
			</div>
		</div>
		<div class="margin-right-block">
			<!-- margin notes for reference block here -->
		</div>
	</div>

</body>

</html>