<html>

<head>

	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>

	<link rel="shortcut icon" href="images/icon.ico">
	<style type="text/css">
		body {
			background-color: #f5f9ff;
		}

		/* Hide both math displays initially, will display based on JS detection */
		.mathjax-mobile,
		.mathml-non-mobile {
			display: none;
		}

		/* Show the MathML content by default on non-mobile devices */
		.show-mathml .mathml-non-mobile {
			display: block;
		}

		.show-mathjax .mathjax-mobile {
			display: block;
		}

		.content-margin-container {
			display: flex;
			width: 100%;
			/* Ensure the container is full width */
			justify-content: left;
			/* Horizontally centers the children in the container */
			align-items: center;
			/* Vertically centers the children in the container */
		}

		.main-content-block {
			width: 70%;
			/* Change this percentage as needed */
			max-width: 1100px;
			/* Optional: Maximum width */
			background-color: #fff;
			border-left: 1px solid #DDD;
			border-right: 1px solid #DDD;
			padding: 8px 8px 8px 8px;
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		}

		.margin-left-block {
			font-size: 14px;
			width: 15%;
			/* Change this percentage as needed */
			max-width: 130px;
			/* Optional: Maximum width */
			position: relative;
			margin-left: 10px;
			text-align: left;
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			padding: 5px;
		}

		.margin-right-block {
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			font-size: 14px;
			width: 25%;
			/* Change this percentage as needed */
			max-width: 256px;
			/* Optional: Maximum width */
			position: relative;
			text-align: left;
			padding: 10px;
			/* Optional: Adds padding inside the caption */
		}

		img {
			max-width: 100%;
			/* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
		}

		.my-video {
			max-width: 100%;
			/* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
		}

		/* Hide both video displays initially, will display based on JS detection */
		.vid-mobile,
		.vid-non-mobile {
			display: none;
		}

		/* Show the video content by default on non-mobile devices */
		.show-vid-mobile .vid-mobile {
			display: block;
		}

		.show-vid-non-mobile .vid-non-mobile {
			display: block;
		}

		a:link,
		a:visited {
			color: #0e7862;
			/*#1367a7;*/
			text-decoration: none;
		}

		a:hover {
			color: #24b597;
			/*#208799;*/
		}

		h1 {
			font-size: 18px;
			margin-top: 4px;
			margin-bottom: 10px;
		}

		table.header {
			font-weight: 300;
			font-size: 17px;
			flex-grow: 1;
			width: 70%;
			max-width: calc(100% - 290px);
			/* Adjust according to the width of .paper-code-tab */
		}

		table td,
		table td * {
			vertical-align: middle;
			position: relative;
		}

		table.paper-code-tab {
			flex-shrink: 0;
			margin-left: 8px;
			margin-top: 8px;
			padding: 0px 0px 0px 8px;
			width: 290px;
			height: 150px;
		}

		.layered-paper {
			/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
			box-shadow:
				0px 0px 1px 1px rgba(0, 0, 0, 0.35),
				/* The top layer shadow */
				5px 5px 0 0px #fff,
				/* The second layer */
				5px 5px 1px 1px rgba(0, 0, 0, 0.35),
				/* The second layer shadow */
				10px 10px 0 0px #fff,
				/* The third layer */
				10px 10px 1px 1px rgba(0, 0, 0, 0.35);
			/* The third layer shadow */
			margin-top: 5px;
			margin-left: 10px;
			margin-right: 30px;
			margin-bottom: 5px;
		}

		hr {
			height: 1px;
			/* Sets the height of the line to 1 pixel */
			border: none;
			/* Removes the default border */
			background-color: #DDD;
			/* Sets the line color to black */
		}

		div.hypothesis {
			width: 80%;
			background-color: #EEE;
			border: 1px solid black;
			border-radius: 10px;
			-moz-border-radius: 10px;
			-webkit-border-radius: 10px;
			font-family: Courier;
			font-size: 18px;
			text-align: center;
			margin: auto;
			padding: 16px 16px 16px 16px;
		}

		div.citation {
			font-size: 0.8em;
			background-color: #fff;
			padding: 10px;
			height: 200px;
		}

		.fade-in-inline {
			position: absolute;
			text-align: center;
			margin: auto;
			-webkit-mask-image: linear-gradient(to right,
					transparent 0%,
					transparent 40%,
					black 50%,
					black 90%,
					transparent 100%);
			mask-image: linear-gradient(to right,
					transparent 0%,
					transparent 40%,
					black 50%,
					black 90%,
					transparent 100%);
			-webkit-mask-size: 8000% 100%;
			mask-size: 8000% 100%;
			animation-name: sweepMask;
			animation-duration: 4s;
			animation-iteration-count: infinite;
			animation-timing-function: linear;
			animation-delay: -1s;
		}

		.fade-in2-inline {
			animation-delay: 1s;
		}

		.inline-div {
			position: relative;
			display: inline-block;
			/* Makes both the div and paragraph inline-block elements */
			vertical-align: top;
			/* Aligns them at the top, you can adjust this to middle, bottom, etc., based on your needs */
			width: 50px;
			/* Optional: Adds space between the div and the paragraph */
		}

		.section-divider {
			height: 1px;
			background-color: #ccc;
			margin: 32px 0 12px 0;
		}

		.section-title {
			font-size: 24px;
			font-weight: 600;
			margin: 12px 0 16px 0;
			letter-spacing: -0.2px;
		}
	</style>

	<title>Adaptive-Depth Transformers for Efficient and Robust ECG Classification</title>
	<meta property="og:title" content="Adaptive-Depth Transformers for Efficient and Robust ECG Classification" />
	<meta charset="UTF-8">
</head>

<body>

	<div class="content-margin-container">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<table class="header" align=left>
				<tr>
					<td colspan=4>
						<span
							style="font-size: 32px; font-family: 'Helvetica', Courier, monospace; /* Adds fallbacks */">Adaptive-Depth
							Transformers for Efficient and Robust ECG Classification</span>
					</td>
				</tr>`
				<tr>
					<td align=left>
						<span style="font-size:17px"><a href="https://github.com/awcheng23">Alice Cheng</a></span>
					</td>
					<td align=left>
						<span style="font-size:17px"><a href="https://github.com/anchris24">Anne Christiono</a></span>
					</td>
				<tr>
					<td colspan=4 align=left><span style="font-size:18px">Final project for 6.7960, MIT</span></td>
				</tr>
			</table>
		</div>
		<div class="margin-right-block">
		</div>
	</div>

	<div class="content-margin-container" id="hero">
		<div class="margin-left-block">
			<!-- table of contents here -->
			<div style="position:fixed; max-width:inherit; top:max(20%,120px)">
				<b style="font-size:16px">Outline</b><br><br>
				<a href="#intro">Introduction</a><br><br>
				<a href="#prior_work">Prior Work</a><br><br>
				<a href="#methodology">Methodology</a><br><br>
				<a href="#experimental_results">Experimental Results</a><br><br>
				<a href="#implications_and_limitations">Implications and Limitations</a><br><br>
				<a href="#conclusion">Conclusion</a><br><br>
			</div>
		</div>
		<div class="main-content-block">
			<!--You can embed an image like this:-->
			<img src="./images/morphology_101_140.png" width=512px />
		</div>
		<div class="margin-right-block">
			<b>Figure 1.</b> Example ECG waveform illustrating key morphological components, including P waves, QRS
			complexes,
			T waves, PR and ST segments, and the RR interval between successive beats, which together define the
			temporal structure that arrhythmia classifiers must learn to interpret.
		</div>
	</div>

	<div class="content-margin-container" id="intro">
		<div class="margin-left-block">
		</div>

		<div class="main-content-block">

			The source code for the work described in this study can be found <a href="">XXXXXXX ADD
				XXXXXXX.</a><br><br>
			<div class="section-divider"></div>
			<h1 class="section-title">Introduction</h1>
			Electrocardiograms (ECGs) are a cornerstone of cardiac diagnostics, widely used to detect arrhythmias
			such as atrial fibrillation, premature ventricular contractions, and ST-segment deviations. In recent
			years, deep learning models‚Äîparticularly convolutional and transformer architectures‚Äîhave demonstrated
			high accuracy in ECG classification. However, most of these models process all input segments uniformly,
			applying the same computational depth regardless of signal complexity <a href="#ref_1">[1]</a>. As a result,
			clean or simple ECG
			segments are often over-processed, while complex or noisy segments may not receive sufficient analysis.
			This ‚Äúone-size-fits-all‚Äù approach is inefficient, particularly in contexts where energy and latency are
			constrained, such as wearable monitors or bedside diagnostic devices. <br><br>

			<img src="./images/transformer_intro.jpg" width=600px />

			Adaptive computation presents a promising alternative. By allowing models to dynamically decide how much
			processing to allocate to each input, adaptive-depth architectures can potentially reduce unnecessary
			computation while maintaining accuracy. In natural language processing and computer vision, mechanisms
			such as Adaptive Computation Time (ACT) and adaptive halting in transformers have demonstrated that
			models can allocate more computation to difficult or ambiguous inputs, achieving efficiency gains and
			providing interpretable insights into input complexity. <br><br>

			Despite these advances, adaptive computation remains largely unexplored in the context of biomedical
			signals. ECGs are inherently variable: rhythms differ in morphology, duration, and susceptibility to
			noise. An adaptive model could, in principle, allocate fewer layers to simple sinus rhythms while using
			deeper processing for irregular or artifact-laden segments. This could not only improve computational
			efficiency but also reveal interpretable patterns linking model behavior to clinical signal
			characteristics. <br><br>

			This project investigates whether an adaptive halting transformer can dynamically allocate computation
			across ECG segments, comparing it to a fixed-depth baseline. Specifically, we examine whether
			adaptive-depth models can reduce average computation without sacrificing diagnostic accuracy, whether
			computation correlates with input difficulty or noise, and whether depth allocation provides insight
			into local versus global feature usage. By addressing these questions, we aim to provide a
			framework-level understanding of resource-aware deep learning for ECG classification.
			<br><br>

		</div>
		<div class="margin-right-block" style="transform: translate(0%, -20%);">
			<!-- you can move the margin notes up and down with translate -->
			<b>Figure 2.</b> From <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12293">Shah et
				al. (2024)
			</a>: <i>ECG-TransCovNet</i>. Features are extracted from ECG signals using a convolutional neural network
			and passed into a vanilla transformer to detect arrhythmias.
		</div>
	</div>


	<!-- <div class="margin-right-block">
		<b>Figure 2.</b> From <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12293">Shah et
			al. (2024)
		</a>: <i>ECG-TransCovNet</i>. A ViT splits an image into
		patches, encodes them with positional embeddings, processes them through a transformer encoder, and uses a
		classification head to predict image classes.
	</div>
	</div> -->


	<div class="content-margin-container" id="prior-work">
		<div class="margin-left-block"></div>

		<div class="main-content-block">
			<div class="section-divider"></div>
			<h1 class="section-title">Prior Work</h1>

			Automated ECG classification has evolved significantly with deep learning, beginning with convolutional and
			recurrent architectures and moving toward transformer-based approaches. Early methods typically applied
			convolutional networks to ECG waveforms, sometimes transforming the signals into spectral or time-frequency
			representations to better capture morphological and frequency-domain features. These models effectively
			classify common arrhythmias and establish strong benchmark performance, but they process all segments
			uniformly, applying the same computational resources to simple and complex signals alike. [<a
				href="#ref_ullah">2</a>] This limits
			efficiency and offers little insight into which inputs require more processing. <br><br>

			More recent transformer-based models have demonstrated that self-attention can capture long-range
			dependencies across multiple heartbeats, improving the detection of arrhythmias that depend on temporal
			context rather than single-beat morphology. Hybrid designs that combine convolutional layers for local
			feature extraction with transformers for global context have also shown that integrating both local and
			long-range information enhances classification accuracy [<a href="#ref_akan">3</a>]. While these models
			achieve high performance, they
			still operate with a fixed number of layers for every input, ignoring variability in segment difficulty or
			noise. As a result, they may over-process simple segments while under-analyzing challenging or noisy
			windows, and provide limited interpretability regarding which portions of the signal drive
			predictions.<br><br>

			Recent approaches also process continuous ECG segments end-to-end, simultaneously detecting and classifying
			heartbeats without explicit segmentation. By modeling inter-beat dependencies directly, these methods reduce
			preprocessing complexity and capture more holistic temporal information. Nonetheless, these too maintain a
			fixed computational depth, treating all segments equally regardless of clinical complexity or signal
			quality. This leaves potential efficiency gains unexploited and limits the model‚Äôs ability to adapt to
			challenging inputs.<br><br>

			Outside ECG-specific work, adaptive computation has been explored in machine learning more broadly.
			Mechanisms such as Adaptive Computation Time (ACT) allow models to dynamically allocate processing steps per
			input, halting early on simpler cases and devoting more computation to difficult ones [<a
				href="#ref_graves">4</a>]. Extensions of this
			idea to transformer architectures have demonstrated that adaptive halting can reduce average computational
			cost while preserving accuracy, and can also reveal interpretable correlations between input difficulty and
			computation depth.<br><br>

			Applying adaptive computation to ECG analysis is particularly promising because cardiac signals vary widely
			in morphology, rhythm, and noise. An adaptive-depth transformer could allocate fewer layers to
			straightforward sinus rhythms, while dedicating more processing to arrhythmias with complex or ambiguous
			patterns. This dynamic allocation offers several advantages: improved computational efficiency, better
			handling of noisy or low-confidence inputs, and insights into which features or time spans drive
			classification decisions.<br><br>

			Altogether, prior work in CNNs, RNNs, and transformers establishes the feasibility and high accuracy of
			automated ECG classification, while adaptive computation in other domains demonstrates the benefits of
			variable-depth processing. Our proposed approach combines these insights: it leverages transformers to
			capture local and global ECG features while introducing adaptive halting, enabling input-dependent
			computation. This framework addresses the limitations of fixed-depth models and provides a resource-aware,
			interpretable, and robust paradigm for ECG classification.<br><br>
		</div>

		<div class="margin-right-block">
			Margin note: situate your work at the intersection of ECG modelling, transformer architectures, and adaptive
			computation.
		</div>
	</div>


	<div class="content-margin-container">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="section-divider"></div>
			<h1 class="section-title" id="methodology">Methodology</h1>

			<i>Dataset and Preprocessing:</i><br><br>
			All experiments use the MIT-BIH Atrial Fibrillation Database
			([<a href="#ref_moody_mark_1983">5</a>], [<a href="#ref_physionet_afdb">6</a>]),
			comprising 25 long-term ECG recordings, each approximately 10 hours in duration, sampled at 250 Hz. Each
			record contains two ECG channels accompanied by beat-level rhythm annotations indicating normal sinus rhythm
			(N), atrial fibrillation (AFIB), atrial flutter (AFL), and AV junctional rhythm (J). We use only the first
			channel (MLII or V1 depending on record) for all experiments.<br><br>

			Preprocessing consists of three stages. First, we apply a 4th-order Butterworth bandpass filter with cutoff
			frequencies 0.5‚Äì45 Hz to remove baseline wander and high-frequency noise, applied at the native 250 Hz
			sampling rate to preserve temporal alignment with beat annotations. Second, each entire recording is min-max
			normalized to the range [0,1], ensuring amplitude consistency within each patient record while preserving
			inter-patient variability. Third, we segment the continuous ECG into non-overlapping fixed-length 30-second
			windows with a
			30-second stride. Each 30-second window at 250 Hz contains 7500 samples. Windows are labeled as normal
			(class
			0) if all annotated beats within the window are marked 'N', and abnormal (class 1) if at least one beat
			carries an AFIB, AFL, or J annotation. This produces a binary classification task distinguishing normal
			sinus rhythm from arrhythmic episodes.<br><br>

			The dataset is split 70/15/15 by patient into training, validation, and test sets, ensuring that no patient
			appears in multiple splits. This yields 19,672 training windows, 4,216 validation windows, and 4,216 test
			windows. The class distribution is imbalanced (~60% normal, ~40% abnormal), so we compute balanced class
			weights inversely proportional to class frequencies and apply them during training via weighted
			cross-entropy loss. No upsampling or data augmentation is performed, preserving the natural class
			distribution in all sets.<br><br>

			<hr>
			<h1>Fixed-Depth Baseline Model</h1>

			Our baseline is a fixed-depth hybrid architecture combining convolutional patch embedding with a standard
			transformer encoder. The model consists of four components: (1) CNN-based patch embedding, (2) positional
			encoding, (3) a stack of 4 transformer encoder layers, and (4) an MLP classification head.<br><br>

			<b>Patch Embedding:</b> The input ECG segment <i>x</i> ‚àà ‚Ñù<sup>1√ó7500</sup> is first processed by a 1D
			convolutional layer with 32 filters, kernel size 7, stride 1, and padding 3, followed by batch normalization
			and ReLU activation. This extracts local temporal features while preserving sequence length. A second 1D
			convolutional layer with 128 filters, kernel size 75, and stride 75 performs non-overlapping patchification,
			reducing the 7500-sample sequence into 100 patches, each represented by a 128-dimensional embedding.
			Formally, the patchification step computes <i>Z</i><sub>0</sub> ‚àà ‚Ñù<sup>100√ó128</sup>, where each row
			corresponds to a 75-sample (0.3-second) temporal patch.<br><br>

			<b>Positional Encoding:</b> Sinusoidal positional encodings are added to each patch embedding to inject
			temporal ordering information:
			<br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				PE(<i>pos</i>, 2<i>i</i>) = sin(<i>pos</i> / 10000<sup>2<i>i</i>/128</sup>)<br>
				PE(<i>pos</i>, 2<i>i</i> + 1) = cos(<i>pos</i> / 10000<sup>2<i>i</i>/128</sup>)<br>
			</div>
			<br>
			where <i>pos</i> ‚àà {0, ..., 99} is the patch index and <i>i</i> ‚àà {0, ..., 63} indexes the embedding
			dimension. The resulting patch sequence <i>Z</i><sub>0</sub> + PE serves as input to the
			transformer.<br><br>

			<b>Transformer Encoder:</b> The model applies 4 identical transformer encoder layers sequentially. Each
			layer consists of multi-head self-attention (2 heads, 64-dimensional key/query/value projections per head,
			total dimension 128) followed by a position-wise feedforward network (FFN) with hidden dimension 256. Each
			sub-layer uses residual connections and layer normalization. Dropout (rate 0.1) is applied after attention
			and FFN layers. Formally, for layer <i>l</i>, the transformation is:
			<br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>Z</i>'<sub><i>l</i></sub> = LayerNorm(<i>Z</i><sub><i>l</i>‚àí1</sub> +
				MultiHeadAttention(<i>Z</i><sub><i>l</i>‚àí1</sub>))<br>
				<i>Z</i><sub><i>l</i></sub> = LayerNorm(<i>Z</i>'<sub><i>l</i></sub> +
				FFN(<i>Z</i>'<sub><i>l</i></sub>))<br>
			</div>
			<br>
			After layer 4, we obtain <i>Z</i><sub>4</sub> ‚àà ‚Ñù<sup>100√ó128</sup>.<br><br>

			<b>Classification Head:</b> We perform mean pooling over all 100 patches to obtain a global representation
			<i>z</i> = (1/100) Œ£<sub><i>p</i></sub> <i>Z</i><sub>4</sub>[<i>p</i>] ‚àà ‚Ñù<sup>128</sup>. This is passed
			through a two-layer MLP: first a linear layer (128 ‚Üí 128) with ReLU and dropout (0.1), then a final linear
			layer (128 ‚Üí 2) producing logits for binary classification. The model is trained with weighted cross-entropy
			loss:
			<br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>L</i><sub>task</sub> = ‚àí Œ£<sub><i>c</i></sub> <i>w</i><sub><i>c</i></sub> <i>y</i><sub><i>c</i></sub>
				log œÉ(<i>f</i>(<i>x</i>)<sub><i>c</i></sub>)<br>
			</div>
			<br>
			where <i>w</i><sub><i>c</i></sub> are balanced class weights, <i>y</i> is the one-hot label, and œÉ is
			softmax. We use AdamW optimizer with learning rate 3√ó10<sup>‚àí4</sup>, weight decay 10<sup>‚àí4</sup>, and
			gradient clipping at norm 1.0. Training proceeds for 20 epochs with batch size 32.<br><br>

			The fixed-depth baseline applies all 4 transformer layers to every input, providing a strong but
			computationally uniform baseline. Total parameters: ~240k trainable.<br><br>

			<hr>
			<h1>Adaptive-Depth Transformer Model</h1>

			The adaptive model shares the same CNN patch embedding, positional encoding, and classification head as the
			baseline, but replaces the fixed transformer stack with an Adaptive Computation Time (ACT)-style halting
			mechanism [<a href="#ref_graves">4</a>]. This enables per-sample, per-layer halting decisions, allowing
			simple inputs to exit early while complex inputs traverse more layers.<br><br>

			<b>Halting Mechanism:</b> At each transformer layer <i>l</i> ‚àà {0, 1, 2, 3}, after applying self-attention
			and feedforward transformations, we compute a global representation via mean pooling:
			<i>z</i><sub><i>l</i></sub> = (1/100) Œ£<sub><i>p</i></sub> <i>Z</i><sub><i>l</i></sub>[<i>p</i>] ‚àà
			‚Ñù<sup>128</sup>. The halting probability for layer <i>l</i> is computed as:
			<br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>h</i><sub><i>l</i></sub> = œÉ(Œ≥ ¬∑ <i>z</i><sub><i>l</i></sub>[0] ‚àí Œ≤)
			</div>
			<br>
			where œÉ(¬∑) is the sigmoid function, <i>z</i><sub><i>l</i></sub>[0] is the first scalar dimension of the
			global embedding, and Œ≥ (gamma) and Œ≤ (center) are learned scalar parameters initialized to 1.0. This scalar
			halting score represents the model's confidence that sufficient processing has occurred. The final layer
			(layer 3) forces halting by setting <i>h</i><sub>3</sub> = 1.<br><br>

			<b>ACT State Updates:</b> For each sample, we maintain three state variables: cumulative halting mass
			<i>c</i> (initially 0), remainder mass <i>R</i> (initially 1), and an active mask (initially 1). At each
			layer, we update:
			<br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>c</i> ‚Üê <i>c</i> + <i>h</i><sub><i>l</i></sub> ¬∑ mask<br>
				reached = (<i>c</i> ‚â• 1 ‚àí Œµ) ‚àß (mask = 1)<br>
				not_reached = (<i>c</i>
				< 1 ‚àí Œµ) ‚àß (mask=1)<br>
			</div>
			<br>
			where Œµ = 0.05 is a small threshold. Samples are classified into two cases:<br><br>

			<b>Case 1 (Halted):</b> If reached = 1, the sample halts at this layer. We accumulate the layer's output
			weighted by the remainder:
			<br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				Œ¥<sub>1</sub> = <i>R</i> ¬∑ <i>z</i><sub><i>l</i></sub>
			</div>
			<br>
			The ponder cost œÅ increments by 1 (for this layer) plus <i>R</i> (for the fractional remaining
			computation).<br><br>

			<b>Case 2 (Continuing):</b> If not_reached = 1, the sample continues processing. We accumulate the
			output weighted by the halting probability:
			<br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				Œ¥<sub>2</sub> = <i>h</i><sub><i>l</i></sub> ¬∑ <i>z</i><sub><i>l</i></sub><br>
				<i>R</i> ‚Üê <i>R</i> ‚àí <i>h</i><sub><i>l</i></sub><br>
				mask ‚Üê ùüô(<i>c</i>
				< 1 ‚àí Œµ) </div>
					<br>
					The ponder cost œÅ increments by 1 (one full layer executed).<br><br>

					The final output representation is the weighted sum of all layer contributions:
					<br><br>
					<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
						<b>output</b> = Œ£<sub><i>l</i>=0</sub><sup>3</sup> (Œ¥<sub>1,<i>l</i></sub> +
						Œ¥<sub>2,<i>l</i></sub>)
					</div>
					<br>
					This output is passed to the same MLP classification head as the baseline to produce logits.<br><br>

					<b>Training Objective:</b> The adaptive model is trained with a composite loss combining task
					accuracy and computational cost:
					<br><br>
					<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
						<i>L</i> = <i>L</i><sub>task</sub> + Œ±<sub>p</sub> ¬∑ ùîº[œÅ]
					</div>
					<br>
					where <i>L</i><sub>task</sub> is the weighted cross-entropy loss (same as baseline), œÅ is the
					per-sample ponder cost (effective depth in layers), and Œ±<sub>p</sub> = 5√ó10<sup>‚àí4</sup> is the
					ponder loss weight. The ponder term encourages the model to halt early when possible, balancing
					accuracy against computation. The halting parameters Œ≥ and Œ≤ are learned via backpropagation along
					with all other model weights.<br><br>

					During inference, each sample adaptively traverses a variable number of layers (between 1 and 4),
					with early halting on simple inputs reducing both FLOPs and latency. We track the per-sample depth œÅ
					to analyze computational allocation across input classes and signal complexity. The adaptive model
					has the same parameter count as the baseline (~240k), but effective computation per sample is
					reduced on average.<br><br>

					<b>Evaluation Metrics:</b> For both models, we report test accuracy, per-class accuracy (normal vs.
					abnormal), and test loss. For the adaptive model, we additionally track: (1) average depth œÅ overall
					and per class, (2) median and standard deviation of depth per class, (3) fraction of samples
					reaching full depth (œÅ ‚â• 4), (4) effective FLOPs per sample (full-depth FLOPs √ó œÅ/4), and (5)
					per-sample inference time. These metrics enable hypothesis testing regarding whether the model
					allocates less computation to normal samples and more to abnormal samples, whether computational
					savings are achieved without accuracy loss, and whether depth correlates with input
					difficulty.<br><br>

			</div>
			<div class="margin-right-block">
				A caption for the video could go here.
			</div>
		</div>

		<div class="content-margin-container" id="implications_and_limitations">
			<div class="margin-left-block">
			</div>
			<div class="main-content-block">
				<h1>Implications and limitations</h1>
				Let's end with some discussion of the implications and limitations.
			</div>
			<div class="margin-right-block">
			</div>
		</div>

		<div class="content-margin-container" id="citations">
			<div class="margin-left-block">
			</div>
			<div class="main-content-block">
				<div class='citation' id="references" style="height:auto"><br>
					<span style="font-size:16px">References:</span><br><br>
					<a id="ref_1"></a>[1] <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12293">
						ECG-TransCovNet: A hybrid transformer model for accurate arrhythmia detection using
						Electrocardiogram signals</a>,
					Shah, et al., 2024<br><br>
					<a id="ref_ullah"></a>[2] <a href="https://arxiv.org/abs/2005.06902">
						Classification of Arrhythmia by Using Deep Learning with 2-D ECG Spectral Image
						Representation</a>,
					Ullah, et al., 2020<br><br>
					<a id="ref_akan"></a>[3] <a href="https://arxiv.org/abs/2401.05434">

						ECGformer: Leveraging transformer for ECG heartbeat arrhythmia classification</a>,
					Akan, et al., 2024<br><br>
					<a id="ref_graves"></a>[4] <a href="https://arxiv.org/abs/1603.08983">
						Adaptive Computation Time for Recurrent Neural Networks</a>, Graves, 2016<br><br>
					<a id="ref_moody_mark_1983"></a>[5] <a
						href="http://ecg.mit.edu/george/publications/afib-cinc-1983.pdf">
						A new method for detecting atrial fibrillation using RR intervals</a>,
					Moody and Mark, 1983<br><br>
					<a id="ref_physionet_afdb"></a>[6] <a href="https://physionet.org/content/afdb/1.0.0/">
						MIT-BIH Atrial Fibrillation Database</a>, Goldberger et al., 2000 <br><br>


				</div>
			</div>
			<div class="margin-right-block">
				<!-- margin notes for reference block here -->
			</div>
		</div>

</body>

</html>