<html>

<head>
	<meta charset="UTF-8">
	<title>Adaptive Computation Transformers for Efficient ECG Time Series Classification</title>

	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>

	<link rel="shortcut icon" href="images/icon.ico">
	<style type="text/css">
		body {
			background-color: #f5f9ff;
		}

		/* Hide both math displays initially, will display based on JS detection */
		.mathjax-mobile,
		.mathml-non-mobile {
			display: none;
		}

		/* Show the MathML content by default on non-mobile devices */
		.show-mathml .mathml-non-mobile {
			display: block;
		}

		.show-mathjax .mathjax-mobile {
			display: block;
		}

		.content-margin-container {
			display: flex;
			width: 100%;
			/* Ensure the container is full width */
			justify-content: left;
			/* Horizontally centers the children in the container */
			align-items: center;
			/* Vertically centers the children in the container */
		}

		.main-content-block {
			width: 70%;
			/* Change this percentage as needed */
			max-width: 1100px;
			/* Optional: Maximum width */
			background-color: #fff;
			padding: 8px 8px 8px 8px;
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		}

		.margin-left-block {
			font-size: 16px;
			width: 15%;
			/* Change this percentage as needed */
			max-width: 130px;
			/* Optional: Maximum width */
			position: relative;
			margin-left: 10px;
			text-align: left;
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			padding: 5px;
		}

		.margin-right-block {
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			font-size: 14px;
			width: 25%;
			/* Change this percentage as needed */
			max-width: 256px;
			/* Optional: Maximum width */
			position: relative;
			text-align: left;
			padding: 10px;
			/* Optional: Adds padding inside the caption */
		}

		img {
			max-width: 100%;
			/* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
		}

		.my-video {
			max-width: 100%;
			/* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
		}

		/* Hide both video displays initially, will display based on JS detection */
		.vid-mobile,
		.vid-non-mobile {
			display: none;
		}

		/* Show the video content by default on non-mobile devices */
		.show-vid-mobile .vid-mobile {
			display: block;
		}

		.show-vid-non-mobile .vid-non-mobile {
			display: block;
		}

		a:link,
		a:visited {
			color: #0e7862;
			/*#1367a7;*/
			text-decoration: none;
		}

		a:hover {
			color: #24b597;
			/*#208799;*/
		}

		h1 {
			font-size: 18px;
			margin-top: 4px;
			margin-bottom: 10px;
		}

		table.header {
			font-weight: 300;
			font-size: 17px;
			flex-grow: 1;
			width: 70%;
			max-width: calc(100% - 290px);
			margin-top: 20px;
			/* Adjust according to the width of .paper-code-tab */
		}

		table td,
		table td * {
			vertical-align: middle;
			position: relative;
		}

		table.paper-code-tab {
			flex-shrink: 0;
			margin-left: 8px;
			margin-top: 8px;
			padding: 0px 0px 0px 8px;
			width: 290px;
			height: 150px;
		}

		.layered-paper {
			/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
			box-shadow:
				0px 0px 1px 1px rgba(0, 0, 0, 0.35),
				/* The top layer shadow */
				5px 5px 0 0px #fff,
				/* The second layer */
				5px 5px 1px 1px rgba(0, 0, 0, 0.35),
				/* The second layer shadow */
				10px 10px 0 0px #fff,
				/* The third layer */
				10px 10px 1px 1px rgba(0, 0, 0, 0.35);
			/* The third layer shadow */
			margin-top: 5px;
			margin-left: 10px;
			margin-right: 30px;
			margin-bottom: 5px;
		}

		hr {
			height: 1px;
			/* Sets the height of the line to 1 pixel */
			border: none;
			/* Removes the default border */
			background-color: #DDD;
			/* Sets the line color to black */
		}

		div.hypothesis {
			width: 80%;
			background-color: #EEE;
			border: 1px solid black;
			border-radius: 10px;
			-moz-border-radius: 10px;
			-webkit-border-radius: 10px;
			font-family: Courier;
			font-size: 18px;
			text-align: center;
			margin: auto;
			padding: 16px 16px 16px 16px;
		}

		div.citation {
			font-size: 0.8em;
			background-color: #fff;
			padding: 10px;
			height: 200px;
		}

		.fade-in-inline {
			position: absolute;
			text-align: center;
			margin: auto;
			-webkit-mask-image: linear-gradient(to right,
					transparent 0%,
					transparent 40%,
					black 50%,
					black 90%,
					transparent 100%);
			mask-image: linear-gradient(to right,
					transparent 0%,
					transparent 40%,
					black 50%,
					black 90%,
					transparent 100%);
			-webkit-mask-size: 8000% 100%;
			mask-size: 8000% 100%;
			animation-name: sweepMask;
			animation-duration: 4s;
			animation-iteration-count: infinite;
			animation-timing-function: linear;
			animation-delay: -1s;
		}

		.fade-in2-inline {
			animation-delay: 1s;
		}

		.inline-div {
			position: relative;
			display: inline-block;
			/* Makes both the div and paragraph inline-block elements */
			vertical-align: top;
			/* Aligns them at the top, you can adjust this to middle, bottom, etc., based on your needs */
			width: 50px;
			/* Optional: Adds space between the div and the paragraph */
		}

		.section-divider {
			height: 1px;
			background-color: #ccc;
			margin: 32px 0 12px 0;
		}

		.main-section-divider {
			height: 2px;
			background-color: #999;
			margin: 8px 0 20px 0;
		}

		.section-title {
			font-size: 24px;
			font-weight: 600;
			margin: 12px 0 16px 0;
			letter-spacing: -0.2px;
		}
	</style>

	<title>Adaptive Computation Transformers for Efficient ECG Time Series Classification</title>
	<meta property="og:title"
		content="Adaptive Computation Transformers for Efficient ECG Time Series Classification" />
	<meta charset="UTF-8">
</head>

<body>

	<div class="content-margin-container">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<table class="header" align=left>
				<tr>
					<td colspan=4>
						<span
							style="font-size: 32px; font-family: 'Helvetica', Courier, monospace; font-weight: bold;">Adaptive
							Computation Transformers for Efficient ECG Time Series Classification</span>
					</td>
				</tr>`
				<tr>
					<td align=left>
						<span style="font-size:17px"><a href="https://github.com/awcheng23">Alice Cheng</a></span>
					</td>
					<td align=left>
						<span style="font-size:17px"><a href="https://github.com/anchris24">Anne Christiono</a></span>
					</td>
				<tr>
					<td colspan=4 align=left><span style="font-size:18px">Final project for 6.7960, MIT</span></td>
				</tr>
			</table>
		</div>
		<div class="margin-right-block">
		</div>
	</div>

	<div class="content-margin-container" id="hero">
		<div class="margin-left-block">
			<!-- table of contents here -->
			<div style="position:fixed; max-width:inherit; top:max(20%,120px)">
				<b style="font-size:20px">Outline</b><br><br>
				<a href="#intro">Introduction</a><br><br>
				<a href="#related-work">Related Work</a><br><br>
				<a href="#methodology">Methodology</a><br><br>
				<a href="#experimental_results">Experimental Results</a><br><br>
				<a href="#discussion">Discussion</a><br><br>
				<a href="#conclusion">Conclusion</a><br><br>
			</div>
		</div>


	</div>

	<div class="content-margin-container" id="intro">
		<div class="margin-left-block">
		</div>

		<div class="main-content-block">
			<h1 class="section-title">Introduction</h1>
			Time-series data appear across scientific, medical, and industrial domains, where the goal is often to
			analyze long sequences for patterns, trends, or anomalies. Unlike static inputs, time-series signals evolve
			over time and contain dependencies spanning short, medium, and long temporal ranges. Many real-world
			tasks‚Äîforecasting, anomaly detection, event classification‚Äîrequire models that can process large volumes of
			sequential data.<br><br>

			One important physiological time series are electrocardiogram (ECG) signals. ECGs record the electrical
			activity of the heart over time and are widely used to detect arrhythmias (irregular heartbeats), which can
			often an be an underlying symptom of more severe heart problems. Detecting arrhythmias such as atrial
			fibrillation requires analyzing tens of seconds to hours of ECG data, even though clinically relevant
			anomalies may occupy only small portions of the signal. In recent
			years, deep learning models&mdash;particularly convolutional and transformer architectures&mdash;have
			demonstrated high accuracy in ECG classification.<br><br>

			<img src="./images/arrhythmia_example.png" style="max-width: 90%; height: auto;"><br>

			Because these time series are long and densely sampled, computational efficiency is crucial. For ECG signal
			analysis, most deep learning models process all input segments uniformly,
			applying the same computational depth regardless of signal complexity <a href="#ref_1">[1]</a>. This
			"one-size-fits-all" approach is inefficient, particularly in contexts such as wearable monitors or real-time
			monitoring.<br><br>

			Adaptive computation presents a promising alternative. By allowing models to dynamically decide how much
			processing to allocate to each input, adaptive architectures can potentially reduce unnecessary computation
			while maintaining accuracy. Unambiguous segments can halt early or bypass blocks, while difficult or noisy
			segments receive additional computation. This enables input-dependent routing of information through the
			network. In natural language processing and computer vision, adaptive mechanisms such as early-exit
			transformers, halting networks, and learned sparsity gates have demonstrated that models can learn when more
			computation is necessary. However, adaptive computation remains largely unexplored for biomedical time
			series like ECGs, where efficiency and interpretability are equally important. This motivates our
			investigation into adaptive transformers for ECG anomaly detection.<br><br>

			This project investigates whether adaptive computation transformers can accurately detect arrhythmias in ECG
			signaals while dynamically allocating computation across the segments Specifically, we examine whether
			adaptive depth and selection models can reduce average computation without sacrificing diagnostic accuracy,
			the relationship between FLOPs and input class, and the possibility of depth allocation providing insight
			into local versus global feature usage. By addressing these questions, we aim to provide a framework-level
			understanding of resource-aware deep learning for ECG classification.
			<br><br>

		</div>
		<div class="margin-right-block" style="transform: translate(0%, -40%);">
			<b>Figure 1.</b> Example ECG signal showing normal sinus rhythm and atrial fibrillation. The irregular pattern in the arrhythmic segment demonstrates the variability that makes anomaly detection
			challenging in long time series.
		</div>
	</div>


	<div class="content-margin-container" id="related-work">
		<div class="margin-left-block"></div>

		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Related Work</h1> Automated ECG classification has evolved
			significantly with deep learning, beginning with convolutional and
			recurrent architectures and moving toward transformer-based approaches. Deep learning methods typically
			apply
			convolutional networks to ECG waveforms, sometimes transforming the signals into spectral or time-frequency
			representations to better capture morphological and frequency-domain features [<a
				href="#ref_ullah">2</a>].<br><br>

			More recent transformer-based models have demonstrated that self-attention can capture long-range
			dependencies across multiple heartbeats, improving the detection of arrhythmias that depend on temporal
			context rather than single-beat morphology. Hybrid designs that combine convolutional layers for local
			feature extraction with transformers for global context have also shown that integrating both local and
			long-range information enhances classification accuracy [<a href="#ref_akan">3</a>]. While these models
			achieve high performance, they operate with a fixed number of layers for every input, ignoring variability
			in segment difficulty or
			noise. This limits efficiency and offers little insight into which portions of the signal drive
			predictions.<br><br>

			Outside ECG-specific work, there have been numerous ways to improve transformer efficiency. Weight sharing,
			using the same learned parameters across multiple layers, reduces model size and computation while
			maintaining performance [<a href="#ref_share">4</a>]. Sparse attention mechanisms limit the number of token
			interactions, focusing computation on the most relevant parts of the input. These techniques improve
			efficiency but do not adapt computation based on input complexity [<a href="#ref_sparse">5</a>].<br><br>

			Mechanisms such as Adaptive Computation Time (ACT) for RNNs allow models to dynamically allocate processing
			steps per
			input, halting early on simpler cases and devoting more computation to difficult ones [<a
				href="#ref_graves">6</a>]. Extensions of this idea to vision transformer architectures include adaptive
			token halting, where low-importance spatial tokens do not progress to deeper layers and are removed from
			computation during inference time. This reduces computational
			cost across depth and has demonstrated preserved accuracy, also revealing interpretable correlations between
			input difficulty and computation depth [<a href="#ref_avit">7</a>]. <br><br>

			Another adaptive approach involves learning class-relevant tokens, essentially reducing the number of tokens
			processed. More commonly seen in image classification tasks, the transformer dynamically identifies the most
			informative regions of an input by learning which patch embeddings are most relevant for the target class.
			Instead of processing every patch uniformly, the model assigns importance scores to each patch and retains
			only those that contribute meaningfully to the prediction. This allows the model to concentrate
			computational resources where they matter most [<a href="#ref_jiang">8</a>].<br><br>

			We want to explore adaptive computation methods for ECG signal analysis because arrhythmic episodes can
			often occupy only small portions of an otherwise normal signal, providing a framework for efficient anomaly
			detection in long time series signals. An adaptive transformer could learn to allocate fewer layers to
			straightforward sinus rhythms, or process only patches that correspond to ECG signal morphology, such as the
			QRS complex. <br><br>

			Altogether, prior work in CNNs, RNNs, and transformers establishes the feasibility and high accuracy of
			automated ECG classification, and adaptive computation in other domains demonstrates the benefits of
			variable-depth processing. Our proposed approach combines these insights for time-series classification.
			We leverage CNNs and transformers to
			capture local and global ECG context while incorporating adaptive computation mechanisms to create a
			classifier with input-dependent
			computation. This framework addresses the limitations of fixed-depth models and provides a
			resource-aware,
			interpretable, and robust paradigm for ECG signal classification.<br><br>

		</div>
		<div class="margin-right-block">
		</div>
	</div>


	<div class="content-margin-container" id="methodology">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Methodology</h1>

			<i>Data and Preprocessing</i><br><br>
			All experiments use the MIT-BIH Atrial Fibrillation Database,
			comprising 23 ten-hour ECG recordings sampled
			at 250 Hz [<a href="#ref_physionet_afdb">9</a>]. We use the first channel of the recording to stay
			consistent with prior work. Each signal has a
			list of rhythm annotations that mark continuous intervals of time. We segment each signal into
			non-overlapping 30-second windows (7500 samples), labeled as
			normal (class 0) if the segment lies entirely in a sinus rhythm (N) interval, and abnormal (class 1) if it
			overlaps with an AFIB (atrial fibrillation), AFL (atrial flutter), or J (AV junctional rhythm)
			interval.<br><br>

			We preprocess the signals with a Butterworth bandpass filter (0.5-45 Hz) for noise and min-max normalization
			to the range [0,1]. The dataset is split into 70% (19,672 segments) for training, 15% (4,216) validation,
			and 15% (4,216) test.
			Balanced class weights are applied during training due to slight class imbalance (~60% normal, ~40%
			abnormal).<br><br>

			All experiments in this study were conducted with NVIDIA L40S and H200 GPUs.<br><br>

			<hr>
			<h1>Fixed Depth Baseline Model</h1>

			The baseline architecture comprises four components: CNN-based patch embedding, sinusoidal positional
			encoding, four transformer encoder layers, and an MLP classification head. The model converts each ECG
			segment into a sequence of learned (fixed-length) patch embeddings using two convolutional layers to capture
			local morphology. Positional encodings are added, and the sequence is processed by a four-layer transformer
			encoder. The resulting patch representations are mean-pooled to form a global embedding, which a small MLP
			uses to predict the final arrhythmia label. The model is trained with weighted cross-entropy loss, using the
			AdamW
			optimizer with learning rate 3√ó10<sup>‚àí4</sup>, weight decay 10<sup>‚àí4</sup>, gradient clipping at norm
			1.0.<br><br>

			<hr>
			<h1>Adaptive Depth Transformer Model</h1>

			The adaptive model shares the same CNN patch embedding, positional encoding, and classification head as the
			baseline, but replaces the fixed transformer with per-layer halting mechanism. We use two variants: <b>(i)
				non
				weight
				sharing</b>, where each of the four transformer blocks has its own parameters, and <b>(ii)
			    weight
				sharing</b>, where a single transformer block is reused across all depths. FLOPs reported at "full
			depth" assume all four layers are
			executed, and effective FLOPs during inference depend on the learned halting pattern. We take inspiration from token halting in vision transformers, but adapt the mechanism for entire layers [<a href="#ref_avit">7</a>].
            <br><br>

			<b>Halting Mechanism:</b> At each transformer layer <i>l</i> ‚àà {0, 1, 2, 3}, after computing the global
			representation <i>z</i><sub><i>l</i></sub> = (1/100) Œ£<sub><i>p</i></sub>
			<i>Z</i><sub><i>l</i></sub>[<i>p</i>], the halting probability is computed as:
			<br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>h</i><sub><i>l</i></sub> = œÉ(Œ≥ ¬∑ <i>z</i><sub><i>l</i></sub>[0] ‚àí Œ≤)
			</div>
			<br>
			where Œ≥ and Œ≤ are learned scalar parameters initialized to 1.0, and the final layer forces halting
			by setting <i>h</i><sub>3</sub> = 1. For each sample, we maintain three state variables: cumulative halting
			mass <i>c</i> (initially 0), remainder mass <i>R</i> (initially 1), and an active mask (initially 1). At
			each layer, we update <i>c</i> ‚Üê <i>c</i> + <i>h</i><sub><i>l</i></sub> ¬∑ mask. If <i>c</i> ‚â• 1 ‚àí Œµ (where Œµ
			= 0.05), the sample halts and contributes <i>R</i> ¬∑ <i>z</i><sub><i>l</i></sub> to the output; otherwise,
			it continues processing and contributes <i>h</i><sub><i>l</i></sub> ¬∑ <i>z</i><sub><i>l</i></sub> to the
			output while updating <i>R</i> ‚Üê <i>R</i> ‚àí <i>h</i><sub><i>l</i></sub>. The final representation is the
			weighted sum <b>output</b> = Œ£<sub><i>l</i></sub> (Œ¥<sub>1,<i>l</i></sub> + Œ¥<sub>2,<i>l</i></sub>).<br><br>

			<b>Training Objective:</b> The adaptive model is trained with a composite loss combining task accuracy and
			computational cost:<br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>L</i> = <i>L</i><sub>task</sub> + Œ±<sub>p</sub> ¬∑ ùîº[œÅ]
			</div>
			<br>
			where œÅ is the per-sample ponder cost and Œ±<sub>p</sub> = 5√ó10<sup>‚àí4</sup> is
			the ponder loss weight. The halting parameters Œ≥ and Œ≤ are learned via backpropagation along with all other
			model weights. During inference, each sample adaptively traverses between 1 and 4 layers, with œÅ tracked for subsequent analysis.<br><br>

			<hr>
			<h1>Adaptive Selection Transformer Model</h1>
			While the adaptive-halting model uses early stopping to dynamically reduce depth, the adaptive-selection
			model takes a complementary approach by employing learned sparsity gates to skip computation at the patch,
			head, and block levels within a fixed four-layer depth. The model introduces small per-layer
			gating
			MLPs (for patch, head, and block decisions). These extra networks increase the number of parameters and
			full-depth FLOPs.<br><br>

			<b>Gate Architecture:</b> At each layer, the model produces three learnable gate functions:<br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>M</i><sub>p,<i>l</i></sub> ‚àà (0,1)<sup>100</sup>: patch (token) selection at layer <i>l</i><br>
				<i>M</i><sub>h,<i>l</i></sub> ‚àà (0,1)<sup>H</sup>: attention head selection at layer <i>l</i><br>
				<i>M</i><sub>b,<i>l</i></sub> ‚àà (0,1): block-wide gating at layer <i>l</i>
			</div>
			<br>
			These gates are computed per-sample from accumulated context <i>Z</i><sub><i>l</i></sub> via a small MLP
			that processes <i>z</i><sub>proc</sub> = ReLU(W<sub>1</sub> ¬∑ <i>Z</i><sub><i>l</i></sub> +
			<i>b</i><sub>1</sub>) and then generates logits for each gate type. Gumbel-sigmoid relaxation enables
			differentiable training, and thresholding at inference produces discrete sparsity patterns.<br><br>

			<b>Gate Application and FLOPs:</b> The patch and attention head gates mask token embeddings and attention heads respectively. The block gate modulates residual connections as X ‚Üê X + <i>M</i><sub>b,<i>l</i></sub> ¬∑
			(attention<sub>out</sub> + ff<sub>out</sub>). FLOPs are estimated as:<br><br>

			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				N<sub>eff,<i>l</i></sub> = 1 + <i>M</i><sub>p,<i>l</i></sub>[1:].sum()<br>
				FLOPs<sub><i>l</i></sub> = (N<sub>eff,<i>l</i></sub> / 100) ¬∑ (<i>M</i><sub>h,<i>l</i></sub>.sum() /
				<i>H</i>) ¬∑ <i>M</i><sub>b,<i>l</i></sub> ¬∑ FLOPs<sub>dense,<i>l</i></sub><br>
				compute_fraction = Œ£<sub><i>l</i></sub> FLOPs<sub><i>l</i></sub> / (4 ¬∑ FLOPs<sub>dense</sub>)
			</div>
			<br>
			The resulting compute fraction reflects how much of the full model was actually used, with lower values indicating more aggressive sparsity.<br><br>

			<b>Training Objective:</b> Like the adaptive depth model, the selection model is trained with a composite
			loss balancing task accuracy and computation: <br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>L</i> = <i>L</i><sub>task</sub> + Œ±<sub>p</sub> ¬∑ ùîº[compute_fraction]
			</div>
			<br>
			where Œ±<sub>p</sub> = 5√ó10<sup>‚àí4</sup> (same as the halting model). The decision network and gate
			projections do add to the total parameter count, but the masking ensures computations are comparable to the other models.<br><br>


			<hr>
			<h1>Research Hypotheses</h1>

			<b>H1: Computational Efficiency.</b> Can adaptive models reduce average computational cost without
			sacrificing classification accuracy for time seres?<br>
			Since we embed the signal similar to how vision transformers process image tokens, we hypothesize that both adaptive approaches can still achieve comparable test accuracy compared to the fixed baseline,
			while using fewer FLOPs per sample on average.<br><br>

			<b>H2: Input-Dependent Computation.</b> Do adaptive models allocate computation differentially based on
			input characteristics?<br>
			We hypothesize that normal sinus rhythm segments will require lower average depth/FLOPs than arrhythmic segments, reflecting the intuition that, when a cardiologist is manually examining, regular rhythms likely require less
			processing than complex or irregular patterns. <br><br>

			<!-- <b>H3: Correlation with Signal Complexity.</b> Does the computation allocated by adaptive models correlate
			with intrinsic signal characteristics?<br>
			We hypothesize that samples with higher variance, lower signal-to-noise ratio, or atypical morphology will
			require traversing more layers or retaining more patches/heads/blocks, demonstrating sensitivity to
			variability, noise level, and morphological complexity.<br><br> -->

			<b>H3: Interpretability and Feature Usage.</b> Do adaptive mechanisms provide interpretable insights into
			which temporal or spatial features drive classification?<br>
			We hypothesize that for the halting model, early halting will correspond to local feature sufficiency while
			late halting indicates reliance on global temporal context, and for the selection model, patch and attention
			head retention patterns will reveal task-relevant time spans and feature dependencies.<br><br>
		</div>
		<div class="margin-right-block">
		</div>
	</div>



	<div class="content-margin-container" id="experimental_results">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Experimental Results</h1>

			We trained all four models on the MIT-BIH Atrial Fibrillation Database and evaluated their performance
			across computational efficiency, accuracy, and model complexity. Our results demonstrate that adaptive
			computation reduces FLOPs and parameters while maintaining or improving classification accuracy.<br><br>

			<h1>Model Performance Comparison</h1>
			<img src="./images/test_performance.png" alt="FLOPs over training iterations"
				style="max-width: 80%; height: auto;"><br>

			From Table 1, we see some efficiency accuracy trade-offs. The adaptive model without weight sharing provides
			the most balanced improvement. The weight-sharing version, while slightly less accurate, cuts the parameter
			count nearly in half and still lowers computation. The adaptive selection model behaves differently.
			Although its full-depth computation is higher, its learned sparsity allows it to operate at a fraction of
			the cost during inference, achieving the largest efficiency gains overall while also delivering the highest
			accuracy. Together, these results show that both early-halting and learned-sparsity strategies can
			meaningfully reduce computational load, with each variant offering a different balance of efficiency, model
			size, and performance. <br><br>
		</div>
		<div class="margin-right-block">
			<b>Table 1.</b> <i> Comprehensive model performance metrics.</i> All models are evaluated on the same
			test
			set
			(AFDB, 2-class: normal vs. atrial fibrillation).
		</div>
	</div>

	<div class="content-margin-container" id="discussion">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Discussion</h1>

			<h1>FLOP Analysis</h1>
			<div style="text-align: center; margin: 20px 0;">
				<img src="./images/flops_over_time.png" alt="FLOPs over training iterations"
					style="max-width: 90%; height: auto;">

			</div>

			In Figure 2, we see the FLOP count for the adaptive models drop below the fixed baseline early in training
			and remain lower. Both adaptive depth models quickly learn to halt earlier, settling into lower-cost
			computation after the initial few hundred iterations. The non‚Äìweight-sharing version converges to a stable,
			moderately reduced compute level, whereas the weight-sharing model fluctuates more but still maintains lower
			FLOPs than the baseline. The adaptive-selection model exhibits the strongest reduction. Its FLOPs drop
			sharply at the start as the gating mechanism learns, but due to its framework, it already begins with a
			sparse computation compared the baseline and learns to decrease even further. Overall, we see that as
			training progresses, the adaptive mechanisms learn when full processing is unnecessary and automatically
			compress computation in a data-dependent way.<br><br>


			<h1>Learning Stability</h1>

			We track the stability of the three adaptive models by recording the variance of FLOPs across training
			iterations in Figure 3. The adaptive depth (no weight sharing) model (green) displays the lowest and most
			consistent variance, indicating a stable halting policy that quickly converges to a predictable computation
			pattern. In contrast, the weight-sharing variant (orange) shows persistently higher variance, reflecting the
			added difficulty of learning halting behavior when all layers share parameters. The model must balance reuse
			with flexible depth, leading to noisier adaptation. The adaptive selection model (red) exhibits the highest
			volatility, especially in the early and mid-training phases, due to its stochastic Gumbel-sigmoid gating,
			which actively explores sparse configurations before settling into a more stable pattern. Deterministic
			depth-based halting produces the most stable learning dynamics, while learning sparsity introduces greater
			variability as the model searches for efficient pruning strategies.

			<div style="text-align: center; margin: 20px 0;">
				<img src="./images/learning_stability_variance.png" alt="Learning stability and variance analysis"
					style="max-width: 60%; height: auto;">
			</div><br>


			<hr>
			<h1>Adaptive Depth Model</h1>
			Ponder loss is the regularization term used to penalize models that use too many computational steps. We see
			in Figure 4 that ponder loss steadily decreases for both adaptive depth models as training progresses,
			indicating that the halting mechanism is learning to use fewer transformer layers on average. Early in
			training, both models explore deeper computation, resulting in higher ponder penalties as they frequently
			traverse more layers. The non-weight-sharing model converges to a consistently lower ponder loss, once again
			reflecting more stable halting behavior, whereas the weight-sharing model maintains a higher and more
			variable ponder loss due to the shared parameters needing to generalize across multiple depths. This
			supports the hypothesis that adaptive models successfully learn to reduce computation without being
			explicitly instructed where to halt.<br><br>

			<div style="text-align: center; margin: 20px 0;">
				<img src="./images/average_ponder_loss.png" alt="Average ponder loss over training"
					style="max-width: 70%; height: auto;"> <br><br>
				<img src="./images/ponder_loss_by_class.png" style="max-width: 35%; height: auto;">
			</div>
			Interestingly, the normal class shows higher ponder loss on average than the arrhythmia class, which we can
			see in Figure 5. Since ponder loss depends on how many layers a sample traverses and how the halting mass is
			accumulated. If a sample distributes its halting probability more gradually across layers, the effective
			ponder cost increases. In contrast, arrhythmia segments may trigger more decisive halting behavior,
			explaining the lower average ponder cost, assigning larger halting probabilities at one or two layers, and
			leading to a lower ponder penalty. Thus, this supports input-dependent computation, but the opposite of what we hypothesized in <b>H2</b>. The higher
			ponder loss for normal signals suggests that the model expresses greater uncertainty about when to halt on
			clean sinus rhythms, while arrhythmic inputs elicit stronger, more confident halting decisions.

			<hr>
			<h1>Adaptive Selection Model</h1>
			The adaptive selection model assigns each input patch a learned continuation probability. In Figure 6, the model begins training at roughly 30%
			activity, due to the compounding effects of all 3&mdash;patch, head, and block&mdash;selections being limited and our choice of the Gumbel-Softmax distribution.
			Over the course of training, the percentage of the model in use steadily declines and fluctuates between 10-25%. We observe that the model is exploring accuracy-sparsity trade-offs. Eventually, the model converges at approximately 14% activity. Despite the minimal parameter usage, the adaptive selection model still achieved 99.26% test accuracy, furthering illustrating <b>H1</b>. This also invites future work with light transformer models and their
			performance on this task, since the model performed well with majority units inactive.<br><br>

			<div style="text-align: center; margin: 20px 0;">
				<img src="./images/selection_model_activity.png" alt="Selection model active patches over training"
					style="max-width: 70%; height: auto;"> <br><br>
				<img src="./images/low_high_compute_grid.png" alt="Low and high compute examples"
					style="max-width: 70%; height: auto;">
			</div>

			In Figure 7, we evaluate the patches of five test segments with the lowest computational cost against the
			five with the highest, highlighting which temporal patches were retained by the adaptive selection model. The patches are sparsely distributed, but typically cover the entire QRS complex, and either the proceeding P-wave or
            following T-wave. This aligns with clinical knowledge that these features are most informative for arrhythmia detection and <b>H3</b>.
			The model did not exhibit dramatic differences in the number of patches selected across these
			two groups, and their FLOPs per test pass were within the same order of magnitude. This shows that for the adaptive selection model, there was not a significant difference in compute resource allocation. We note that five of the
			samples that required the least computation were normal sinus rhythm, whereas the heavy-compute set contained a mix of normal and
			abnormal cases (two normal and three arrhythmic).

			The fact that some normal
			samples also require high compute indicates that the model is responding not just to rhythm class, but possibly to
			broader signal characteristics‚Äîsuch as noise, irregular morphology, or ambiguous local features.

		</div>
		<div class="margin-right-block">
			<p style="transform: translate(0%, -1640%);">
				<b>Figure 2.</b> <i>FLOPs per forward pass across training.</i> We record the number of FLOPs for each
				model at each training step.
			</p>

			<p style="transform: translate(0%, -555%);">
				<b>Figure 3.</b> <i>Variance in FLOPs over training for three adaptive models. </i>Adaptive depth
				remains the most stable, while weight-sharing increases variance and adaptive selection shows the
				highest volatility due to stochastic gating.
			</p>

			<p style="transform: translate(0%, -170%);">
				<b>Figure 4.</b> <i>Average Ponder Loss during training.</i> Shows the decline in ponder loss for both
				adaptive depth models, indicating learned reduction in computation over time.
			</p>

			<p style="transform: translate(0%, 90%);">
				<b>Figure 5.</b> <i>Per-Class Ponder Loss Distribution.</i> Visualizes the distribution of ponder loss
				values for normal and arrhythmic classes on the test set across models.

			</p>


			<p style="transform: translate(0%, 740%);">
				<b>Figure 6.</b> <i>Selection model active parameter fraction across training steps. </i> Model starts at ~30%
				activity and then drops off and demonstrates learned extreme sparsity.
			</p>

			<p style="transform: translate(0%, 1100%);">
				<b>Figure 7.</b> <i> Patch-Level Computation Patterns. </i> Patches retained by the model for the lowest-
				and highest-compute segments by the adaptive selection model. 
			</p>

		</div>
	</div>

	<div class="content-margin-container" id="conclusion">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Conclusion</h1>

			This work demonstrates that transformer-based ECG models can achieve significant computational
			efficiency through input-dependent routing mechanisms. Both adaptive depth and learned sparsity approaches
			reduce average model depth without sacrificing diagnostic accuracy. Adaptive depth without weight sharing
			achieves 29.9% FLOPs
			reduction while maintaining 98.93% accuracy compared to the baseline model's 98.81% accuracy, while adaptive
			selection achieves 91.1% reduction at 99.26%
			accuracy. Adaptive selection could serve as a powerful framework for model interpretability, and for signals not as well characterized as ECGs, help determine which parts of the signal to focus on. <br><br>

			From an architectural perspective, this project highlights the relationship between model capacity,
			regularization
			design, and learned computation allocation. However, practical deployment of such methods
			requires addressing several architectural and empirical gaps, such as the end-to-end framework. The
			expressiveness of limited depth could unintentionally constrain feature learning in earlier layers,
			potentially leading to suboptimal representations. Future work should
			investigate the relationship between signal complexity metrics and computation load, as well as layer-wise
			feature specialization through causal analysis and attention visualization. Extending this framework to
			multi-lead recordings and other physiological signals would
			establish whether adaptive depth allocation could become principle for biomedical deep learning.<br><br>

		</div>
		<div class="margin-right-block">
		</div>
	</div>

	<div class="content-margin-container" id="citations">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class='citation' id="references" style="height:auto"><br>
				<span style="font-size:16px">References</span><br><br>
				<a id="ref_1"></a>[1] <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12293">
					ECG-TransCovNet: A hybrid transformer model for accurate arrhythmia detection using
					Electrocardiogram signals</a>,
				Shah, et al., 2024<br><br>
				<a id="ref_ullah"></a>[2] <a href="https://arxiv.org/abs/2005.06902">
					Classification of Arrhythmia by Using Deep Learning with 2-D ECG Spectral Image
					Representation</a>,
				Ullah, et al., 2020<br><br>
				<a id="ref_akan"></a>[3] <a href="https://arxiv.org/abs/2401.05434">

					ECGformer: Leveraging transformer for ECG heartbeat arrhythmia classification</a>,
				Akan, et al., 2024<br><br>
				<a id="ref_share"></a>[4] <a href="https://arxiv.org/abs/1909.11942">
					ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</a>, Lan et al.,
				2019<br><br>
				<a id="ref_sparse"></a>[5] <a href="https://arxiv.org/abs/2406.16747">
					Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers</a>, Lou
				et al., 2024<br><br>
				<a id="ref_graves"></a>[6] <a href="https://arxiv.org/abs/1603.08983">
					Adaptive Computation Time for Recurrent Neural Networks</a>, Graves, 2016<br><br>
				<a id="ref_avit"></a>[7] <a
					href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_A-ViT_Adaptive_Tokens_for_Efficient_Vision_Transformer_CVPR_2022_paper.pdf">
					A-ViT: Adaptive Tokens for Efficient Vision Transformer</a>, Yin et al., 2022 <br><br>
				<a id="ref_jiang"></a>[8] <a href="https://arxiv.org/html/2405.03722v1">
					Class-relevant Patch Embedding Selection for Few-Shot Image Classification</a>, Yuan et al., 2024
				<br><br>
				<a id="ref_physionet_afdb"></a>[9] <a href="https://physionet.org/content/afdb/1.0.0/">
					MIT-BIH Atrial Fibrillation Database</a>, Goldberger et al., 2000 <br><br>

			</div>
		</div>
		<div class="margin-right-block">
			<!-- margin notes for reference block here -->
		</div>
	</div>

</body>

</html>