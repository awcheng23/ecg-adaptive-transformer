<html>

<head>

	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>

	<link rel="shortcut icon" href="images/icon.ico">
	<style type="text/css">
		body {
			background-color: #f5f9ff;
		}

		/* Hide both math displays initially, will display based on JS detection */
		.mathjax-mobile,
		.mathml-non-mobile {
			display: none;
		}

		/* Show the MathML content by default on non-mobile devices */
		.show-mathml .mathml-non-mobile {
			display: block;
		}

		.show-mathjax .mathjax-mobile {
			display: block;
		}

		.content-margin-container {
			display: flex;
			width: 100%;
			/* Ensure the container is full width */
			justify-content: left;
			/* Horizontally centers the children in the container */
			align-items: center;
			/* Vertically centers the children in the container */
		}

		.main-content-block {
			width: 70%;
			/* Change this percentage as needed */
			max-width: 1100px;
			/* Optional: Maximum width */
			background-color: #fff;
			border-left: 1px solid #DDD;
			border-right: 1px solid #DDD;
			padding: 8px 8px 8px 8px;
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		}

		.margin-left-block {
			font-size: 14px;
			width: 15%;
			/* Change this percentage as needed */
			max-width: 130px;
			/* Optional: Maximum width */
			position: relative;
			margin-left: 10px;
			text-align: left;
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			padding: 5px;
		}

		.margin-right-block {
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			font-size: 14px;
			width: 25%;
			/* Change this percentage as needed */
			max-width: 256px;
			/* Optional: Maximum width */
			position: relative;
			text-align: left;
			padding: 10px;
			/* Optional: Adds padding inside the caption */
		}

		img {
			max-width: 100%;
			/* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
		}

		.my-video {
			max-width: 100%;
			/* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
		}

		/* Hide both video displays initially, will display based on JS detection */
		.vid-mobile,
		.vid-non-mobile {
			display: none;
		}

		/* Show the video content by default on non-mobile devices */
		.show-vid-mobile .vid-mobile {
			display: block;
		}

		.show-vid-non-mobile .vid-non-mobile {
			display: block;
		}

		a:link,
		a:visited {
			color: #0e7862;
			/*#1367a7;*/
			text-decoration: none;
		}

		a:hover {
			color: #24b597;
			/*#208799;*/
		}

		h1 {
			font-size: 18px;
			margin-top: 4px;
			margin-bottom: 10px;
		}

		table.header {
			font-weight: 300;
			font-size: 17px;
			flex-grow: 1;
			width: 70%;
			max-width: calc(100% - 290px);
			/* Adjust according to the width of .paper-code-tab */
		}

		table td,
		table td * {
			vertical-align: middle;
			position: relative;
		}

		table.paper-code-tab {
			flex-shrink: 0;
			margin-left: 8px;
			margin-top: 8px;
			padding: 0px 0px 0px 8px;
			width: 290px;
			height: 150px;
		}

		.layered-paper {
			/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
			box-shadow:
				0px 0px 1px 1px rgba(0, 0, 0, 0.35),
				/* The top layer shadow */
				5px 5px 0 0px #fff,
				/* The second layer */
				5px 5px 1px 1px rgba(0, 0, 0, 0.35),
				/* The second layer shadow */
				10px 10px 0 0px #fff,
				/* The third layer */
				10px 10px 1px 1px rgba(0, 0, 0, 0.35);
			/* The third layer shadow */
			margin-top: 5px;
			margin-left: 10px;
			margin-right: 30px;
			margin-bottom: 5px;
		}

		hr {
			height: 1px;
			/* Sets the height of the line to 1 pixel */
			border: none;
			/* Removes the default border */
			background-color: #DDD;
			/* Sets the line color to black */
		}

		div.hypothesis {
			width: 80%;
			background-color: #EEE;
			border: 1px solid black;
			border-radius: 10px;
			-moz-border-radius: 10px;
			-webkit-border-radius: 10px;
			font-family: Courier;
			font-size: 18px;
			text-align: center;
			margin: auto;
			padding: 16px 16px 16px 16px;
		}

		div.citation {
			font-size: 0.8em;
			background-color: #fff;
			padding: 10px;
			height: 200px;
		}

		.fade-in-inline {
			position: absolute;
			text-align: center;
			margin: auto;
			-webkit-mask-image: linear-gradient(to right,
					transparent 0%,
					transparent 40%,
					black 50%,
					black 90%,
					transparent 100%);
			mask-image: linear-gradient(to right,
					transparent 0%,
					transparent 40%,
					black 50%,
					black 90%,
					transparent 100%);
			-webkit-mask-size: 8000% 100%;
			mask-size: 8000% 100%;
			animation-name: sweepMask;
			animation-duration: 4s;
			animation-iteration-count: infinite;
			animation-timing-function: linear;
			animation-delay: -1s;
		}

		.fade-in2-inline {
			animation-delay: 1s;
		}

		.inline-div {
			position: relative;
			display: inline-block;
			/* Makes both the div and paragraph inline-block elements */
			vertical-align: top;
			/* Aligns them at the top, you can adjust this to middle, bottom, etc., based on your needs */
			width: 50px;
			/* Optional: Adds space between the div and the paragraph */
		}

		.section-divider {
			height: 1px;
			background-color: #ccc;
			margin: 32px 0 12px 0;
		}

		.main-section-divider {
			height: 2px;
			background-color: #999;
			margin: 48px 0 20px 0;
		}

		.section-title {
			font-size: 24px;
			font-weight: 600;
			margin: 12px 0 16px 0;
			letter-spacing: -0.2px;
		}
	</style>

	<title>Adaptive Computation Transformers for Efficient ECG Time Series Classification</title>
	<meta property="og:title"
		content="Adaptive Computation Transformers for Efficient ECG Time Series Classification" />
	<meta charset="UTF-8">
</head>

<body>

	<div class="content-margin-container">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<table class="header" align=left>
				<tr>
					<td colspan=4>
						<span
							style="font-size: 32px; font-family: 'Helvetica', Courier, monospace; /* Adds fallbacks */">Adaptive
							Computation Transformers for Efficient ECG Time Series Classification</span>
					</td>
				</tr>`
				<tr>
					<td align=left>
						<span style="font-size:17px"><a href="https://github.com/awcheng23">Alice Cheng</a></span>
					</td>
					<td align=left>
						<span style="font-size:17px"><a href="https://github.com/anchris24">Anne Christiono</a></span>
					</td>
				<tr>
					<td colspan=4 align=left><span style="font-size:18px">Final project for 6.7960, MIT</span></td>
				</tr>
			</table>
		</div>
		<div class="margin-right-block">
		</div>
	</div>

	<div class="content-margin-container" id="hero">
		<div class="margin-left-block">
			<!-- table of contents here -->
			<div style="position:fixed; max-width:inherit; top:max(20%,120px)">
				<b style="font-size:16px">Outline</b><br><br>
				<a href="#intro">Introduction</a><br><br>
				<a href="#prior_work">Prior Work</a><br><br>
				<a href="#methodology">Methodology</a><br><br>
				<a href="#experimental_results">Experimental Results</a><br><br>
				<a href="#implications_and_limitations">Implications and Limitations</a><br><br>
				<a href="#conclusion">Conclusion</a><br><br>
			</div>
		</div>
		<div class="main-content-block">
			<!--You can embed an image like this:-->
			<img src="./images/morphology_101_140.png" width=512px />
		</div>
		<div class="margin-right-block">
			<b>Figure 1.</b> Example ECG waveform illustrating key morphological components, including P waves, QRS
			complexes,
			T waves, PR and ST segments, and the RR interval between successive beats, which together define the
			temporal structure that arrhythmia classifiers must learn to interpret.
		</div>
	</div>

	<div class="content-margin-container" id="intro">
		<div class="margin-left-block">
		</div>

		<div class="main-content-block">

			The source code for the work described in this study can be found <a href="">XXXXXXX ADD
				XXXXXXX.</a><br><br>
			<div class="main-section-divider"></div>
			<h1 class="section-title">Introduction</h1>
			Electrocardiograms (ECGs) are a cornerstone of cardiac diagnostics, widely used to detect arrhythmias
			such as atrial fibrillation, premature ventricular contractions, and ST-segment deviations. In recent
			years, deep learning models‚Äîparticularly convolutional and transformer architectures‚Äîhave demonstrated
			high accuracy in ECG classification. However, most of these models process all input segments uniformly,
			applying the same computational depth regardless of signal complexity <a href="#ref_1">[1]</a>. As a result,
			clean or simple ECG
			segments are often over-processed, while complex or noisy segments may not receive sufficient analysis.
			This ‚Äúone-size-fits-all‚Äù approach is inefficient, particularly in contexts where energy and latency are
			constrained, such as wearable monitors or bedside diagnostic devices. <br><br>

			<img src="./images/transformer_intro.jpg" width=600px />

			Adaptive computation presents a promising alternative. By allowing models to dynamically decide how much
			processing to allocate to each input, adaptive-depth architectures can potentially reduce unnecessary
			computation while maintaining accuracy. In natural language processing and computer vision, mechanisms
			such as Adaptive Computation Time (ACT) and adaptive halting in transformers have demonstrated that
			models can allocate more computation to difficult or ambiguous inputs, achieving efficiency gains and
			providing interpretable insights into input complexity. <br><br>

			Despite these advances, adaptive computation remains largely unexplored in the context of biomedical
			signals. ECGs are inherently variable: rhythms differ in morphology, duration, and susceptibility to
			noise. An adaptive model could, in principle, allocate fewer layers to simple sinus rhythms while using
			deeper processing for irregular or artifact-laden segments. This could not only improve computational
			efficiency but also reveal interpretable patterns linking model behavior to clinical signal
			characteristics. <br><br>

			This project investigates whether an adaptive halting transformer can dynamically allocate computation
			across ECG segments, comparing it to a fixed-depth baseline. Specifically, we examine whether
			adaptive-depth models can reduce average computation without sacrificing diagnostic accuracy, whether
			computation correlates with input difficulty or noise, and whether depth allocation provides insight
			into local versus global feature usage. By addressing these questions, we aim to provide a
			framework-level understanding of resource-aware deep learning for ECG classification.
			<br><br>

		</div>
		<div class="margin-right-block" style="transform: translate(0%, -20%);">
			<!-- you can move the margin notes up and down with translate -->
			<b>Figure 2.</b> From <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12293">Shah et
				al. (2024)
			</a>: <i>ECG-TransCovNet</i>. Features are extracted from ECG signals using a convolutional neural network
			and passed into a vanilla transformer to detect arrhythmias.
		</div>
	</div>


	<div class="content-margin-container" id="prior-work">
		<div class="margin-left-block"></div>

		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title" id="methodology">Related Work</h1> Automated ECG classification has evolved
			significantly with deep learning, beginning with convolutional and
			recurrent architectures and moving toward transformer-based approaches. Deep learning methods typically
			apply
			convolutional networks to ECG waveforms, sometimes transforming the signals into spectral or time-frequency
			representations to better capture morphological and frequency-domain features [<a
				href="#ref_ullah">2</a>].<br><br>

			More recent transformer-based models have demonstrated that self-attention can capture long-range
			dependencies across multiple heartbeats, improving the detection of arrhythmias that depend on temporal
			context rather than single-beat morphology. Hybrid designs that combine convolutional layers for local
			feature extraction with transformers for global context have also shown that integrating both local and
			long-range information enhances classification accuracy [<a href="#ref_akan">3</a>]. While these models
			achieve high performance, they operate with a fixed number of layers for every input, ignoring variability
			in segment difficulty or
			noise. This limits efficiency and offers little insight into which portions of the signal drive
			predictions.<br><br>

			Outside ECG-specific work, there have been numerous ways to improve transformer efficiency. Weight sharing,
			using the same learned parameters across multiple layers, reduces model size and computation while
			maintaining performance [<a href="#ref_share">4</a>]. Sparse attention mechanisms limit the number of token
			interactions, focusing computation on the most relevant parts of the input. These techniques improve
			efficiency but do not adapt computation based on input complexity [<a href="#ref_sparse">5</a>].<br><br>

			Mechanisms such as Adaptive Computation Time (ACT) for RNNs allow models to dynamically allocate processing
			steps per
			input, halting early on simpler cases and devoting more computation to difficult ones [<a
				href="#ref_graves">4</a>]. Extensions of this idea to vision transformer architectures include adaptive
			token halting, where low-importance spatial tokens do not progress to deeper layers and are removed from
			computation during inference time. This reduces computational
			cost across depth and has demonstrated preserved accuracy, also revealing interpretable correlations between
			input difficulty and computation depth [<a href="#ref_avit">5</a>]. <br><br>

			Another adaptive approach involves learning class-relevant tokens, essentially reducing the number of tokens
			processed. More commonly seen in image classification tasks, the transformer dynamically identifies the most
			informative regions of an input by learning which patch embeddings are most relevant for the target class.
			Instead of processing every patch uniformly, the model assigns importance scores to each patch and retains
			only those that contribute meaningfully to the prediction. This allows the model to concentrate
			computational resources where they matter most [<a href="#ref_jiang">6</a>].<br><br>

			We want to explore adaptive computation methods for ECG signal analysis because arrhythmic episodes can
			often occupy only small portions of an otherwise normal signal, providing a framework for efficient anomaly
			detection in long time series signals. An adaptive transformer could learn to allocate fewer layers to
			straightforward sinus rhythms, or process only patches that correspond to ECG signal morphology, such as the
			QRS complex. <br><br>

			Altogether, prior work in CNNs, RNNs, and transformers establishes the feasibility and high accuracy of
			automated ECG classification, and adaptive computation in other domains demonstrates the benefits of
			variable-depth processing. Our proposed approach combines these insights for time-series classification.
			We leverage CNNs and transformers to
			capture local and global ECG context while incorporating adaptive computation mechanisms to create a
			classifier with input-dependent
			computation. This framework addresses the limitations of fixed-depth models and provides a
			resource-aware,
			interpretable, and robust paradigm for ECG signal classification.<br><br>

		</div>
	</div>


	<div class="content-margin-container">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title" id="methodology">Methodology</h1>

			<i>Dataset and Preprocessing:</i><br><br>
			All experiments use the MIT-BIH Atrial Fibrillation Database ([<a href="#ref_moody_mark_1983">5</a>], [<a
				href="#ref_physionet_afdb">6</a>]), comprising 23 ten-hour ECG recordings sampled
			at 250 Hz. We use the first channel of the recording to stay consistent with prior work. Each signal has a
			list of rhythm annotations that mark continuous intervals of time. We segment each signal into
			non-overlapping 30-second windows (7500 samples), labeled as
			normal (class 0) if the segment lies entirely in a sinus rhythm (N) interval, and abnormal (class 1) if it
			overlaps with an AFIB (atrial fibrillation), AFL (atrial flutter), or J (AV junctional rhythm)
			interval.<br><br>

			We preprocess the signals with a Butterworth bandpass filter (0.5‚Äì45 Hz) for noise and min-max normalization
			to the range [0,1]. The dataset is split into 70% (19,672 segments) for training, 15% (4,216) validation,
			and 15% (4,216) test.
			Balanced class weights are applied during training due to class imbalance (~60% normal, ~40%
			abnormal).<br><br>

			<hr>
			<h1>Fixed-Depth Baseline Model</h1>

			The baseline architecture comprises four components: CNN-based patch embedding, sinusoidal positional
			encoding, four transformer encoder layers, and an MLP classification head.<br><br>

			<b>Patch Embedding:</b> The input ECG segment <i>x</i> ‚àà ‚Ñù<sup>1√ó7500</sup> is processed by two 1D
			convolutional layers. The first (32 filters, kernel 7, stride 1, padding 3) extracts local features with
			batch normalization and ReLU activation. The second (128 filters, kernel 75, stride 75) performs
			non-overlapping patchification, yielding <i>Z</i><sub>0</sub> ‚àà ‚Ñù<sup>100√ó128</sup>, where each row
			represents a 0.3-second temporal patch.<br><br>

			<b>Positional Encoding:</b> Sinusoidal positional encodings are added to each patch embedding:
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				PE(<i>pos</i>, 2<i>i</i>) = sin(<i>pos</i> / 10000<sup>2<i>i</i>/128</sup>)<br>
				PE(<i>pos</i>, 2<i>i</i> + 1) = cos(<i>pos</i> / 10000<sup>2<i>i</i>/128</sup>)
			</div>
			<br>
			<b>Transformer Encoder:</b> Four identical encoder layers are applied sequentially. Each layer consists of
			2-head multi-head attention (64 dimensions per head) followed by a feedforward network (hidden dimension
			256), with residual connections, layer normalization, and dropout (0.1) applied after each sub-layer. The
			transformation at layer <i>l</i> is:
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>Z</i>'<sub><i>l</i></sub> = LayerNorm(<i>Z</i><sub><i>l</i>‚àí1</sub> +
				MultiHeadAttention(<i>Z</i><sub><i>l</i>‚àí1</sub>))<br>
				<i>Z</i><sub><i>l</i></sub> = LayerNorm(<i>Z</i>'<sub><i>l</i></sub> +
				FFN(<i>Z</i>'<sub><i>l</i></sub>))
			</div>
			<br>
			<b>Classification Head:</b> We perform mean pooling over all 100 patches to obtain <i>z</i> = (1/100)
			Œ£<sub><i>p</i></sub> <i>Z</i><sub>4</sub>[<i>p</i>] ‚àà ‚Ñù<sup>128</sup>. This global representation is passed
			through a two-layer MLP: a linear layer (128 ‚Üí 128) with ReLU and dropout (0.1), followed by a final linear
			layer (128 ‚Üí 2) producing logits for binary classification.<br><br>

			<b>Training Objective:</b> The model is trained with weighted cross-entropy loss:
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>L</i><sub>task</sub> = ‚àí Œ£<sub><i>c</i></sub> <i>w</i><sub><i>c</i></sub> <i>y</i><sub><i>c</i></sub>
				log œÉ(<i>f</i>(<i>x</i>)<sub><i>c</i></sub>)
			</div>
			<br>
			where <i>w</i><sub><i>c</i></sub> are balanced class weights and œÉ is the softmax function. We use the AdamW
			optimizer with learning rate 3√ó10<sup>‚àí4</sup>, weight decay 10<sup>‚àí4</sup>, gradient clipping at norm 1.0,
			batch size 32, and train for 20 epochs. All inputs traverse all four transformer layers, yielding
			approximately 240k trainable parameters.<br><br>

			<hr>
			<h1>Adaptive-Depth Transformer Model</h1>

			The adaptive model shares the same CNN patch embedding, positional encoding, and classification head as the
			baseline, but replaces the fixed transformer stack with an Adaptive Computation Time (ACT)-style halting
			mechanism [<a href="#ref_graves">4</a>]. This enables per-sample, per-layer halting decisions, allowing
			simple inputs to exit early while complex inputs traverse more layers.<br><br>

			<b>Halting Mechanism:</b> At each transformer layer <i>l</i> ‚àà {0, 1, 2, 3}, after computing the global
			representation <i>z</i><sub><i>l</i></sub> = (1/100) Œ£<sub><i>p</i></sub>
			<i>Z</i><sub><i>l</i></sub>[<i>p</i>], the halting probability is computed as:
			<br><br>
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>h</i><sub><i>l</i></sub> = œÉ(Œ≥ ¬∑ <i>z</i><sub><i>l</i></sub>[0] ‚àí Œ≤)
			</div>
			<br>
			where Œ≥ and Œ≤ are learned scalar parameters initialized to 1.0, and the final layer (layer 3) forces halting
			by setting <i>h</i><sub>3</sub> = 1. For each sample, we maintain three state variables: cumulative halting
			mass <i>c</i> (initially 0), remainder mass <i>R</i> (initially 1), and an active mask (initially 1). At
			each layer, we update <i>c</i> ‚Üê <i>c</i> + <i>h</i><sub><i>l</i></sub> ¬∑ mask. If <i>c</i> ‚â• 1 ‚àí Œµ (where Œµ
			= 0.05), the sample halts and contributes <i>R</i> ¬∑ <i>z</i><sub><i>l</i></sub> to the output; otherwise,
			it continues processing and contributes <i>h</i><sub><i>l</i></sub> ¬∑ <i>z</i><sub><i>l</i></sub> to the
			output while updating <i>R</i> ‚Üê <i>R</i> ‚àí <i>h</i><sub><i>l</i></sub>. The final representation is the
			weighted sum <b>output</b> = Œ£<sub><i>l</i></sub> (Œ¥<sub>1,<i>l</i></sub> + Œ¥<sub>2,<i>l</i></sub>).<br><br>

			<b>Training Objective:</b> The adaptive model is trained with a composite loss combining task accuracy and
			computational cost:
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>L</i> = <i>L</i><sub>task</sub> + Œ±<sub>p</sub> ¬∑ ùîº[œÅ]
			</div>
			<br>
			where œÅ is the per-sample ponder cost (effective depth in layers) and Œ±<sub>p</sub> = 5√ó10<sup>‚àí4</sup> is
			the ponder loss weight. The halting parameters Œ≥ and Œ≤ are learned via backpropagation along with all other
			model weights. During inference, each sample adaptively traverses between 1 and 4 layers, with the
			per-sample depth œÅ tracked for subsequent analysis.<br><br>

			<hr>
			<h1>Adaptive-Selection Transformer Model</h1>
			While the adaptive-halting model uses early stopping to dynamically reduce depth, the adaptive-selection
			model takes a complementary approach by employing learned sparsity gates to skip computation at the patch,
			head, and block levels within a fixed four-layer depth. Rather than deciding whether to process at all, the
			selection model decides what to process, achieving computational savings through fine-grained pruning of
			redundant tokens, attention heads, and entire transformer blocks.<br><br>

			<b>Gate Architecture:</b> At each layer, the model produces three learnable gate functions:
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>M</i><sub>p,<i>l</i></sub> ‚àà (0,1)<sup>100</sup>: patch (token) selection at layer <i>l</i><br>
				<i>M</i><sub>h,<i>l</i></sub> ‚àà (0,1)<sup>H</sup>: attention head selection at layer <i>l</i><br>
				<i>M</i><sub>b,<i>l</i></sub> ‚àà (0,1): block-wide gating at layer <i>l</i>
			</div>
			<br>
			These gates are computed per-sample from accumulated context <i>Z</i><sub><i>l</i></sub> via a small MLP
			that processes <i>z</i><sub>proc</sub> = ReLU(W<sub>1</sub> ¬∑ <i>Z</i><sub><i>l</i></sub> +
			<i>b</i><sub>1</sub>) and then generates logits for each gate type. Gumbel-sigmoid relaxation enables
			differentiable training, while thresholding at inference produces discrete sparsity patterns.<br><br>

			<b>Gate Application and FLOPs:</b> The patch gate masks token embeddings as X<sub>masked</sub> =
			[x<sub>cls</sub>, <i>M</i><sub>p,<i>l</i></sub>[1:] ‚äô x[1:]], where the class token is always retained. The
			head gate masks attention heads via attention<sub>output</sub> ‚äô <i>M</i><sub>h,<i>l</i></sub>, and the
			block gate modulates residual connections as X ‚Üê X + <i>M</i><sub>b,<i>l</i></sub> ¬∑
			(attention<sub>out</sub> + ff<sub>out</sub>). FLOPs are estimated as:
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				N<sub>eff,<i>l</i></sub> = 1 + <i>M</i><sub>p,<i>l</i></sub>[1:].sum()<br>
				FLOPs<sub><i>l</i></sub> = (N<sub>eff,<i>l</i></sub> / 100) ¬∑ (<i>M</i><sub>h,<i>l</i></sub>.sum() /
				<i>H</i>) ¬∑ <i>M</i><sub>b,<i>l</i></sub> ¬∑ FLOPs<sub>dense,<i>l</i></sub><br>
				compute_fraction = Œ£<sub><i>l</i></sub> FLOPs<sub><i>l</i></sub> / (4 ¬∑ FLOPs<sub>dense</sub>)
			</div>
			<br>
			The triple product captures multiplicative savings from pruning tokens, heads, and blocks jointly, allowing
			significant FLOPs reduction when gates cooperate. The compute fraction ranges from 0 to 1, where lower
			values indicate more aggressive pruning.<br><br>

			<b>Training Objective:</b> Like the adaptive-halting model, the selection model is trained with a composite
			loss balancing task accuracy and computation:
			<div style="margin-left: 40px; font-family: 'Courier New', monospace;">
				<i>L</i> = <i>L</i><sub>task</sub> + Œ±<sub>p</sub> ¬∑ ùîº[compute_fraction]
			</div>
			<br>
			where Œ±<sub>p</sub> = 5√ó10<sup>‚àí4</sup> (same as the halting model). The decision network and gate
			projections add approximately 5% to the total parameter count, keeping the model comparable in size to the
			other approaches.<br><br>

			<b>Comparison of Adaptive Models:</b><br><br>
			<table style="width: 100%; border-collapse: collapse; margin-bottom: 20px;">
				<tr style="background-color: #f0f0f0;">
					<td style="border: 1px solid #999; padding: 12px; font-weight: bold; width: 18%;">Aspect</td>
					<td style="border: 1px solid #999; padding: 12px; font-weight: bold; width: 41%;">Adaptive-Halting
					</td>
					<td style="border: 1px solid #999; padding: 12px; font-weight: bold; width: 41%;">Adaptive-Selection
					</td>
				</tr>
				<tr>
					<td style="border: 1px solid #999; padding: 12px; font-weight: bold;">Depth Strategy</td>
					<td style="border: 1px solid #999; padding: 12px;">Variable depth (1‚Äì4 layers) via early stopping
						mechanism</td>
					<td style="border: 1px solid #999; padding: 12px;">Fixed depth (always 4 layers); applies
						intra-layer pruning via learned gate functions</td>
				</tr>
				<tr style="background-color: #fafafa;">
					<td style="border: 1px solid #999; padding: 12px; font-weight: bold;">Decision Mechanism</td>
					<td style="border: 1px solid #999; padding: 12px;"><i>h</i><sub><i>l</i></sub> = œÉ(Œ≥ ¬∑
						<i>z</i><sub><i>l</i></sub>[0] ‚àí Œ≤)<br>Single scalar halting probability computed per layer
					</td>
					<td style="border: 1px solid #999; padding: 12px;"><i>M</i><sub>p,<i>l</i></sub> ‚àà
						(0,1)<sup>100</sup>, <i>M</i><sub>h,<i>l</i></sub> ‚àà (0,1)<sup>H</sup>,
						<i>M</i><sub>b,<i>l</i></sub> ‚àà (0,1)<br>Three hierarchical gate functions applied per layer
					</td>
				</tr>
				<tr>
					<td style="border: 1px solid #999; padding: 12px; font-weight: bold;">Output Aggregation</td>
					<td style="border: 1px solid #999; padding: 12px;"><b>output</b> =
						Œ£<sub><i>l</i>=0</sub><sup>3</sup> (Œ¥<sub>1,<i>l</i></sub> + Œ¥<sub>2,<i>l</i></sub>)<br>Weighted
						sum of layer outputs by halting probabilities</td>
					<td style="border: 1px solid #999; padding: 12px;">X<sub>masked</sub> = [x<sub>cls</sub>,
						<i>M</i><sub>p,<i>l</i></sub> ‚äô x[1:]]<br>Element-wise multiplicative gating of patches, heads,
						and blocks
					</td>
				</tr>
				<tr style="background-color: #fafafa;">
					<td style="border: 1px solid #999; padding: 12px; font-weight: bold;">Loss Function</td>
					<td style="border: 1px solid #999; padding: 12px;"><i>L</i> = <i>L</i><sub>task</sub> +
						Œ±<sub>p</sub> ¬∑ ùîº[œÅ]<br>where œÅ ‚àà [1, 4] represents the ponder cost in layers</td>
					<td style="border: 1px solid #999; padding: 12px;"><i>L</i> = <i>L</i><sub>task</sub> +
						Œ±<sub>p</sub> ¬∑ ùîº[compute_fraction]<br>where compute_fraction = Œ£<sub><i>l</i></sub>
						FLOPs<sub><i>l</i></sub> / (4 ¬∑ FLOPs<sub>dense</sub>)</td>
				</tr>
				<tr>
					<td style="border: 1px solid #999; padding: 12px; font-weight: bold;">Computational Cost</td>
					<td style="border: 1px solid #999; padding: 12px;">FLOPs ‚àù œÅ<br>Average effective depth: 1.1‚Äì4.0
						layers</td>
					<td style="border: 1px solid #999; padding: 12px;">FLOPs<sub><i>l</i></sub> =
						(N<sub>eff,<i>l</i></sub>/100) ¬∑ (Œ±<sub>h,<i>l</i></sub>) ¬∑ <i>M</i><sub>b,<i>l</i></sub> ¬∑
						FLOPs<sub>dense,<i>l</i></sub><br>Typical compute fraction: 0.1‚Äì0.3</td>
				</tr>
				<tr style="background-color: #fafafa;">
					<td style="border: 1px solid #999; padding: 12px; font-weight: bold;">State Management</td>
					<td style="border: 1px solid #999; padding: 12px;">Maintains cumulative halting mass <i>c</i>,
						remainder <i>R</i>, and active mask<br>Halting condition: <i>c</i> ‚â• 1 ‚àí Œµ where Œµ = 0.05</td>
					<td style="border: 1px solid #999; padding: 12px;">Maintains accumulated context vector
						<i>Z</i><sub><i>l</i></sub><br>Decision network processes information from preceding layers
					</td>
				</tr>
				<tr>
					<td style="border: 1px solid #999; padding: 12px; font-weight: bold;">Training Procedure</td>
					<td style="border: 1px solid #999; padding: 12px;">Backpropagation through halting decisions with
						Œ±<sub>p</sub> = 5√ó10<sup>‚àí4</sup> regularization weight</td>
					<td style="border: 1px solid #999; padding: 12px;">Gumbel-sigmoid relaxation during training; hard
						thresholding at inference; Œ±<sub>p</sub> = 5√ó10<sup>‚àí4</sup></td>
				</tr>
				<tr style="background-color: #fafafa;">
					<td style="border: 1px solid #999; padding: 12px; font-weight: bold;">Principal Advantage</td>
					<td style="border: 1px solid #999; padding: 12px;">Interpretable mechanism: terminates processing
						early for simpler inputs</td>
					<td style="border: 1px solid #999; padding: 12px;">Superior FLOPs reduction via multiplicative
						multi-axis pruning (tokens √ó heads √ó blocks)</td>
				</tr>
			</table>

			<hr>
			<h1>Research Hypotheses</h1>

			<b>H1: Computational Efficiency.</b> Can adaptive models reduce average computational cost without
			sacrificing classification accuracy?<br>
			We hypothesize that both adaptive approaches will achieve comparable test accuracy to the fixed baseline
			while using fewer FLOPs per sample on average, as measured by effective depth œÅ or compute_fraction.<br><br>

			<b>H2: Input-Dependent Computation.</b> Do adaptive models allocate computation differentially based on
			input characteristics?<br>
			We hypothesize that normal sinus rhythm segments (class 0) will receive lower average depth or compute
			fraction than arrhythmic segments (class 1), reflecting the intuition that regular rhythms require less
			processing than complex or irregular patterns.<br><br>

			<b>H3: Correlation with Signal Complexity.</b> Does the computation allocated by adaptive models correlate
			with intrinsic signal characteristics?<br>
			We hypothesize that samples with higher variance, lower signal-to-noise ratio, or atypical morphology will
			require traversing more layers or retaining more patches/heads/blocks, demonstrating sensitivity to
			variability, noise level, and morphological complexity.<br><br>

			<b>H4: Interpretability and Feature Usage.</b> Do adaptive mechanisms provide interpretable insights into
			which temporal or spatial features drive classification?<br>
			We hypothesize that for the halting model, early halting will correspond to local feature sufficiency while
			late halting indicates reliance on global temporal context, and for the selection model, patch and attention
			head retention patterns will reveal task-relevant time spans and feature dependencies.<br><br>
		</div>
	</div>



	<div class="content-margin-container" id="experimental_results">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Experimental Results</h1>

			We trained all three models for 20 epochs and evaluated their performance on computational efficiency,
			accuracy, and interpretability. Our results confirm that adaptive computation successfully reduces FLOPs
			while maintaining competitive accuracy, with distinct learning patterns emerging between the two adaptive
			strategies.<br><br>

			<h2>Model Performance and Efficiency Trade-offs</h2>

			<div style="text-align: center; margin: 20px 0;">
				<img src="images/plots/epoch_metrics_comparison.png" alt="Training metrics over epochs"
					style="max-width: 90%; height: auto;">
				<div style="font-size: 14px; color: #666; margin-top: 10px; font-style: italic;">
					<b>Figure 3.</b> Training and validation metrics over 20 epochs. Adaptive-Halting achieves 98.91%
					peak validation accuracy while using ~3.58 layers on average (89.5% of full depth).
					Adaptive-Selection demonstrates progressive compute reduction from 30% to 8.5%, achieving 91.5%
					FLOPs savings at the cost of 2.6 percentage points in validation accuracy.
				</div>
			</div>

			All models converge to high accuracy (98-99% training, 95-98% validation), confirming <b>H1</b>: adaptive
			models reduce computation without major accuracy sacrifice. The Adaptive-Halting model achieves 97.89% test
			accuracy with 12% FLOPs reduction (3.52 avg layers vs. 4.0). The Adaptive-Selection model achieves 95.45%
			test accuracy with <b>91.5% FLOPs reduction</b>, demonstrating an extreme efficiency regime suitable for
			edge deployment.<br><br>

			Notably, the Adaptive-Selection model's compute fraction drops dramatically during training‚Äîfrom ~30% in
			early epochs to just 8.5% by epoch 20‚Äîwhile the Adaptive-Halting model maintains stable ~90% depth
			utilization. This suggests fundamentally different learning strategies: halting learns a consistent
			allocation early, while selection progressively prunes redundant computation after mastering the task.
			<br><br>

			<h2>Class-Dependent Computation Allocation</h2>

			<div style="text-align: center; margin: 20px 0;">
				<img src="images/plots/class_wise_compute_comparison.png" alt="Class-wise compute allocation"
					style="max-width: 90%; height: auto;">
				<div style="font-size: 14px; color: #666; margin-top: 10px; font-style: italic;">
					<b>Figure 4.</b> Per-class FLOPs allocation over training. Both adaptive models allocate
					significantly more compute to abnormal samples (orange) than normal samples (blue), supporting H2.
					The Adaptive-Selection model exhibits more pronounced differentiation (2-3√ó compute ratio) compared
					to Adaptive-Halting (15-20% depth difference).
				</div>
			</div>

			Figure 4 strongly supports <b>H2</b>: adaptive models allocate computation differentially based on input
			class. The Adaptive-Halting model consistently uses ~3.8-4.0 layers for abnormal rhythms versus ~3.2-3.4
			layers for normal rhythms (15-20% difference). The Adaptive-Selection model shows even sharper
			differentiation: normal samples converge to ~5-6% compute fraction while abnormal samples maintain ~12-15%,
			a 2-3√ó multiplier. This aligns with clinical intuition‚Äîarrhythmic patterns require deeper analysis than
			regular sinus rhythms.<br><br>

			<h2>Learning Dynamics and Adaptation Strategies</h2>

			<div style="text-align: center; margin: 20px 0;">
				<img src="images/plots/flops_over_time.png" alt="FLOPs evolution during training"
					style="max-width: 90%; height: auto;">
				<div style="font-size: 14px; color: #666; margin-top: 10px; font-style: italic;">
					<b>Figure 5.</b> Computational cost over training steps. Adaptive-Halting (orange) stabilizes around
					1.7B FLOPs after epoch 3. Adaptive-Selection (green) exhibits monotonic reduction from ~600M to
					~200M FLOPs, demonstrating "progressive pruning" where the model first learns the task, then
					optimizes efficiency.
				</div>
			</div>

			Figure 5 reveals distinct temporal dynamics. The Adaptive-Halting model converges to stable depth allocation
			by epoch 3 (~2000 steps) and maintains ~1.7B FLOPs (¬±10%) thereafter. In contrast, the Adaptive-Selection
			model enters a consistent downward trajectory after epoch 5, monotonically reducing FLOPs by ~60% over
			subsequent training. This "learn then prune" behavior suggests the selection gates require task competence
			before identifying redundant computation.<br><br>

			<div style="text-align: center; margin: 20px 0;">
				<img src="images/plots/efficiency_gains.png" alt="Training progression and efficiency gains"
					style="max-width: 90%; height: auto;">
				<div style="font-size: 14px; color: #666; margin-top: 10px; font-style: italic;">
					<b>Figure 6.</b> Training progression showing efficiency gains (shaded areas). Top panel shows
					absolute FLOPs over training‚Äîboth adaptive models operate below the Fixed baseline, with
					Adaptive-Selection achieving dramatically lower compute (~0.4B FLOPs vs. Fixed's 1.92B). The shaded
					regions quantify cumulative efficiency gains throughout training, with Adaptive-Selection
					accumulating massive savings relative to the Fixed baseline.
				</div>
			</div>

			Figure 6 visualizes the efficiency gains as shaded areas between the Fixed baseline and each adaptive model.
			The Adaptive-Halting model (pink shading) maintains consistent ~10% FLOPs reduction throughout training,
			while the Adaptive-Selection model (orange shading) demonstrates increasing efficiency gains, ultimately
			operating at just ~20% of the Fixed model's compute. These shaded areas represent not just instantaneous
			savings but cumulative computational budget saved over the entire training process‚Äîa critical consideration
			for resource-constrained scenarios.<br><br>

			<h2>Four-Phase Learning Pattern in Adaptive Selection</h2>

			<div style="text-align: center; margin: 20px 0;">
				<img src="images/plots/learning_phases_analysis.png" alt="Learning phases analysis"
					style="max-width: 90%; height: auto;">
				<div style="font-size: 14px; color: #666; margin-top: 10px; font-style: italic;">
					<b>Figure 7.</b> Adaptive-Selection exhibits four distinct learning phases: warmup (steps 0-1000),
					active learning (1000-3000), sparsity emergence (3000-8000), and refinement (8000+). The model
					achieves 60% FLOPs reduction by step 12,000 while maintaining stable performance, with decreasing
					variance indicating convergence to confident pruning decisions.
				</div>
			</div>

			Detailed analysis of the Adaptive-Selection model reveals four learning phases: (1) <b>Warmup</b> (0-1000
			steps): high variance as gates explore; (2) <b>Active Learning</b> (1000-3000): gates stabilize around
			~18-20% compute while task accuracy improves; (3) <b>Sparsity Emergence</b> (3000-8000): progressive
			pruning begins, FLOPs drop 40%; (4) <b>Refinement</b> (8000+): stable efficient regime at ~15% compute with
			low variance. This pattern suggests the model requires task competence before confident pruning, addressing
			<b>H4</b> on interpretability‚Äîthe temporal structure of learning reveals how the model identifies essential
			versus redundant computation.<br><br>

			<h2>Gate Behavior and Computational Stability</h2>

			<div style="text-align: center; margin: 20px 0;">
				<img src="images/plots/selection_model_activity.png" alt="Selection model gate activity"
					style="max-width: 90%; height: auto;">
				<div style="font-size: 14px; color: #666; margin-top: 10px; font-style: italic;">
					<b>Figure 8.</b> Adaptive-Selection model activity during training. The model learns to operate in
					increasingly sparse regimes (12-18% by late training), with dramatic variance reduction indicating
					stable, confident gating decisions. Spikes in activity correlate with difficult batches or class
					imbalance, demonstrating input-dependent adaptation.
				</div>
			</div>

			Figure 8 shows the Adaptive-Selection model progressively reduces average activation from ~30% to ~15%
			while simultaneously decreasing variance (200-step window std drops from 0.15 to 0.02). The occasional
			spikes in compute usage (e.g., around steps 5000, 7000) correspond to batches with higher abnormal-class
			representation or particularly noisy samples, providing evidence for <b>H3</b>: computation correlates with
			signal complexity. The model learns to confidently prune normal samples while preserving resources for
			challenging arrhythmic patterns.<br><br>

			<h2>Summary of Findings</h2>

			<ul style="margin-left: 40px;">
				<li><b>H1 (Efficiency):</b> ‚úì Confirmed. Adaptive-Halting: -0.19% accuracy, -12% FLOPs;
					Adaptive-Selection: -2.6% accuracy, -91.5% FLOPs.</li>
				<li><b>H2 (Input-Dependent Allocation):</b> ‚úì Confirmed. Abnormal samples receive 15-20% more depth
					(halting) or 2-3√ó compute (selection).</li>
				<li><b>H3 (Signal Complexity):</b> ‚äï Partially supported. High-variance batches trigger increased
					compute; requires deeper analysis of SNR and morphology.</li>
				<li><b>H4 (Interpretability):</b> ‚äï Partially supported. Four-phase learning and class-dependent
					allocation reveal interpretable strategies; attention analysis pending.</li>
			</ul>
			<br>

			The results demonstrate that both adaptive strategies successfully learn input-dependent computation, with
			Adaptive-Halting offering conservative efficiency gains and Adaptive-Selection enabling extreme FLOPs
			reduction at modest accuracy cost. The choice depends on deployment constraints: halting for clinical
			accuracy requirements, selection for edge devices.<br><br>

		</div>
	</div>



	<div class="content-margin-container" id="implications_and_limitations">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Implications and Limitations</h1>

			This work shows that adaptive computation can be integrated into transformer-based ECG models to reduce
			average depth without hurting classification performance. The core idea is that the model learns an
			input-dependent stopping rule: easy segments should halt early, while harder or noisier windows should
			trigger deeper layers. When this allocation aligns with signal complexity, it suggests that the model is
			learning a meaningful hierarchy of features‚Äîearly layers capture the broad morphological structure required
			for normal rhythms, while later layers become specialized for ambiguous patterns or arrhythmias that require
			more global temporal context. <br><br>

			There are several limitations worth noting. The halting mechanism we use is intentionally simple, and a more
			expressive controller might learn more nuanced routing behavior. Our comparisons are restricted to a
			fixed-depth transformer baseline, so it is still unclear how adaptive computation stacks up against other
			efficiency methods such as pruning, quantization, or knowledge distillation. We also report compute in terms
			of FLOPs rather than real hardware measurements, meaning the practical speedup on devices like wearables or
			mobile processors remains unverified. Finally, we fix hyperparameters such as the regularization weight Œ±‚Çö;
			understanding how sensitive the halting behavior is to this choice may be important for stability and
			reproducibility.<br><br>

			Future extensions should evaluate adaptive computation across different backbone architectures and other
			physiological time-series tasks, where variability in signal difficulty is similarly high. Combining
			adaptive halting with additional efficiency techniques could further reduce computational cost without
			compromising accuracy. Most importantly, validating results on diverse ECG datasets and measuring actual
			latency and memory usage on hardware would clarify the real-world impact. These directions would help
			determine when adaptive depth truly provides an advantage, both as an efficiency mechanism and as a way to
			interpret how models allocate computation across complex biosignals.<br><br>
		</div>
		<div class="margin-right-block">
		</div>
	</div>

	<div class="content-margin-container" id="conclusion">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class="main-section-divider"></div>
			<h1 class="section-title">Conclusion</h1>

			This work confirms that it is possible to dynamically allocate computation in ECG classification without
			sacrificing diagnostic accuracy, enabling both computational efficiency and input-adaptive behavior.
			Adaptive-depth transformers‚Äîthrough either early halting or learned sparsity gates‚Äîprovide a framework for
			analyzing and comparing the computational requirements of different cardiac signals. This approach not only
			allows for adaptive computation capability but also offers interpretability by revealing which signal
			characteristics drive model depth allocation.<br><br>

			To further investigate the robustness and generalizability of this method, it would be worthwhile to test
			against even more varied and complex datasets, including multi-lead ECGs, diverse arrhythmia types, and
			real-world recordings with varying noise profiles. Additionally, exploring how the computational cost
			regularization (ponder loss or compute_fraction) can be extended to other biomedical signal modalities and
			deep learning architectures would strengthen the applicability of adaptive computation in clinical
			settings.<br><br>

		</div>
		<div class="margin-right-block">
		</div>
	</div>

	<div class="content-margin-container" id="citations">
		<div class="margin-left-block">
		</div>
		<div class="main-content-block">
			<div class='citation' id="references" style="height:auto"><br>
				<span style="font-size:16px">References:</span><br><br>
				<a id="ref_1"></a>[1] <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12293">
					ECG-TransCovNet: A hybrid transformer model for accurate arrhythmia detection using
					Electrocardiogram signals</a>,
				Shah, et al., 2024<br><br>
				<a id="ref_ullah"></a>[2] <a href="https://arxiv.org/abs/2005.06902">
					Classification of Arrhythmia by Using Deep Learning with 2-D ECG Spectral Image
					Representation</a>,
				Ullah, et al., 2020<br><br>
				<a id="ref_akan"></a>[3] <a href="https://arxiv.org/abs/2401.05434">

					ECGformer: Leveraging transformer for ECG heartbeat arrhythmia classification</a>,
				Akan, et al., 2024<br><br>
				<a id="ref_share"></a>[4] <a href="https://arxiv.org/abs/1909.11942">
					ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</a>, Lan et al.,
				2019<br><br>
				<a id="ref_sparse"></a>[5] <a href="https://arxiv.org/abs/2406.16747">
					Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers</a>, Lou
				et al., 2024<br><br>
				<a id="ref_graves"></a>[6] <a href="https://arxiv.org/abs/1603.08983">
					Adaptive Computation Time for Recurrent Neural Networks</a>, Graves, 2016<br><br>
				<a id="ref_avit"></a>[7] <a
					href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_A-ViT_Adaptive_Tokens_for_Efficient_Vision_Transformer_CVPR_2022_paper.pdf">
					A-ViT: Adaptive Tokens for Efficient Vision Transformer</a>, Yin et al., 2022 <br><br>
				<a id="ref_jiang"></a>[8] <a href="https://arxiv.org/html/2405.03722v1">
					Class-relevant Patch Embedding Selection for Few-Shot Image Classification</a>, Yuan et al., 2024
				<br><br>
				<a id="ref_moody_mark_1983"></a>[9] <a href="http://ecg.mit.edu/george/publications/afib-cinc-1983.pdf">
					A new method for detecting atrial fibrillation using RR intervals</a>,
				Moody and Mark, 1983<br><br>
				<a id="ref_physionet_afdb"></a>[10] <a href="https://physionet.org/content/afdb/1.0.0/">
					MIT-BIH Atrial Fibrillation Database</a>, Goldberger et al., 2000 <br><br>

			</div>
		</div>
		<div class="margin-right-block">
			<!-- margin notes for reference block here -->
		</div>
	</div>

</body>

</html>